distinct()
#check for duplicates
WSHFC_cleaned %>%
distinct() %>%
group_by(`Site Name`, Address) %>%
mutate(n = n()) %>%
filter(n > 1) %>%
arrange(`Project Name`, `Site Name`, Address)# %>%
# view()
# ------- DATA FILTER #4 ------- for entries where there are multiple properties with the same total restricted unit count but different other data, select record that seems correct
WSHFC_cleaned <- WSHFC_cleaned %>%
distinct() %>%
filter(!(`Project Name` == "Annobee Apartments, The" & `Site Name` == "Annobee Apartments, The" & `80%` == 43)) %>% #remove this record, keep record with pop served & deeper affordability
filter(!(`Project Name` == "Catalina Apartments" & `Site Name` == "Catalina Apartments" & `40%` == 32)) %>% #remove this record, keep record with pop served & deeper affordability
filter(!(`Project Name` == "Maternity Shelter (Youth Emergency Shelter (YES) North)" & `Site Name` == "Youth Emergency Shelter (YES) North" & `50%` == 8)) #remove this record, keep record with deeper affordability
#check to see if any duplicates remaining - should be 0
WSHFC_cleaned %>%
distinct() %>%
group_by(`Site Name`, Address) %>%
mutate(n = n()) %>%
filter(n > 1) %>%
arrange(`Project Name`, `Site Name`, Address) %>%
view()
# ------- DATA FILTER #5 ------- Small edits/checks
#Filter by InServiceDate - select only records in this vintage year or earlier
WSHFC_cleaned <- WSHFC_cleaned %>%
filter(`First Credit Year or C of O's` <= vintage_year)
#Consolidate SRO and STUDIO into one column
WSHFC_cleaned$STUDIO = WSHFC_cleaned$SRO + WSHFC_cleaned$STUDIO
## 4) clean up field names --------------------------------------------------------------------
#rename columns and add empty columns for data we dont have
WSHFC_cleaned <- WSHFC_cleaned %>%
mutate(DataSource = as.character(NA),
ami_25 = as.numeric("0"),
ami_75 = as.numeric("0"),
ami_85 = as.numeric("0"),
ami_90 = as.numeric("0"),
ami_100 = as.numeric("0"),
ami_120 = as.numeric("0"),
market_rate = as.numeric("0"),
manager_unit = as.numeric("0"),
confidentiality = as.character(NA),
policy = as.character(NA),
tenure = as.character(NA)) %>%
rename(project_id = `ProjectKey`,
project_name = `Project Name`,
property_id = `SiteKey`,
property_name = `Site Name`,
property_owner = `Contractor/Owner Org`,
manager = `Property Management Org`,
city = `City`,
total_units = `Total Project Units`,
total_restricted_units = `Income & Rent Restricted Units`,
in_service_date = `First Credit Year or C of O's`,
ami_20 = `20%`,
ami_30 = `30%`,
ami_35 = `35%`,
ami_40 = `40%`,
ami_45 = `45%`,
ami_50 = `50%`,
ami_60 = `60%`,
ami_65 = `65%`,
ami_70 = `70%`,
ami_80 = `80%`,
bedroom_0 = `STUDIO`,
bedroom_1 = `1 BR`,
bedroom_2 = `2 BR`,
bedroom_3 = `3 BR`,
bedroom_4 = `4 BR`,
bedroom_5 = `5 BR`,
bedroom_unknown = `Unknown`,
bed_count = `GROUP HOME/BED`,
home = `Number of HOME Units`,
HOMEcity = `HOME City`,
HOMEcounty = `HOME County`,
HOMEstate = `HOME State`,
funding_sources = `Funder`,
expiration_date = `Project Expiration Date`,
large_household = `Large Household (4+ pp)`,
site_type = `Site Type`,
senior = `Elderly`,
disabled = `Persons with Disabilities`,
reported_address = `Address`,
county = `County`,
farmworker = `Farmworker`,
homeless = `Homeless`,
transitional = `Transitional`,
data_source = `DataSource`,
veterans = `Veterans`,
zip = `Zip`)
#select only necessary columns and arrange columns
WSHFC_cleaned <- select_and_arrange_columns_function(WSHFC_cleaned)
View(WSHFC_cleaned)
select_and_arrange_columns_function <- function(df){
df <- df %>%
select(any_of(c("data_source",
"project_id",
"project_name",
"property_id",
"property_name",
"property_owner",
"manager",
"in_service_date",
"expiration_date",
"reported_address",
"city",
"zip",
"county",
"total_units",
"total_restricted_units",
"ami_20",
"ami_25",
"ami_30",
"ami_35",
"ami_40",
"ami_45",
"ami_50",
"ami_60",
"ami_65",
"ami_70",
"ami_75",
"ami_80",
"ami_85",
"ami_90",
"ami_100",
"ami_120",
"market_rate",
"manager_unit",
"bedroom_0",
"bedroom_1",
"bedroom_2",
"bedroom_3",
"bedroom_4",
"bedroom_5",
"bedroom_unknown",
"bed_count",
"site_type",
"home",
"HOMEcity",
"HOMEcounty",
"HOMEstate",
"confidentiality",
"policy",
"senior",
"disabled",
"farmworker",
"homeless",
"large_household",
"transitional",
"veterans",
"funding_sources",
"tenure")))
}
## 3) clean WSHFC data --------------------------------------------------------------------
# ------- DATA FILTER #1 ------- filter by county, create/modify fields
WSHFC_cleaned <- WSHFC_raw %>%
filter(County == "Snohomish" | County == "Pierce" | County == "Kitsap")
#create grouped funder column
WSHFC_cleaned %<>%
group_by(`Site Name`, Address) %>%
mutate(Funder = paste(sort(unique(Funder)), collapse = ","))
# ------- DATA FILTER #2 ------- select entry with the largest total restricted unit count
WSHFC_cleaned <- WSHFC_cleaned %>%
group_by(`Site Name`, Address) %>%
slice_max(`Income & Rent Restricted Units`,
n = 1,
with_ties = TRUE) %>%
distinct()
#check for duplicates
WSHFC_cleaned %>%
unique() %>%
group_by(`Site Name`, Address) %>%
mutate(n = n()) %>%
filter(n > 1) %>%
arrange(`Project Name`, `Site Name`, Address) # %>%
#  view()
# ------- DATA FILTER #3 ------- select only entry with latest expiration date
WSHFC_cleaned <- WSHFC_cleaned %>%
group_by(`Site Name`, Address) %>%
slice_max(`Project Expiration Date`,
n = 1,
with_ties = TRUE) %>%
distinct()
#check for duplicates
WSHFC_cleaned %>%
unique() %>%
group_by(`Site Name`, Address) %>%
mutate(n = n()) %>%
filter(n > 1) %>%
arrange(`Project Name`, `Site Name`, Address)# %>%
#  view()
# ------- DATA FILTER #4 ------- select entry with earliest in service date
WSHFC_cleaned <- WSHFC_cleaned %>%
group_by(`Site Name`, Address) %>%
slice_min(`First Credit Year or C of O's`,
n = 1,
with_ties = TRUE) %>%
distinct()
#check for duplicates
WSHFC_cleaned %>%
distinct() %>%
group_by(`Site Name`, Address) %>%
mutate(n = n()) %>%
filter(n > 1) %>%
arrange(`Project Name`, `Site Name`, Address)# %>%
# view()
# ------- DATA FILTER #4 ------- for entries where there are multiple properties with the same total restricted unit count but different other data, select record that seems correct
WSHFC_cleaned <- WSHFC_cleaned %>%
distinct() %>%
filter(!(`Project Name` == "Annobee Apartments, The" & `Site Name` == "Annobee Apartments, The" & `80%` == 43)) %>% #remove this record, keep record with pop served & deeper affordability
filter(!(`Project Name` == "Catalina Apartments" & `Site Name` == "Catalina Apartments" & `40%` == 32)) %>% #remove this record, keep record with pop served & deeper affordability
filter(!(`Project Name` == "Maternity Shelter (Youth Emergency Shelter (YES) North)" & `Site Name` == "Youth Emergency Shelter (YES) North" & `50%` == 8)) #remove this record, keep record with deeper affordability
#check to see if any duplicates remaining - should be 0
WSHFC_cleaned %>%
distinct() %>%
group_by(`Site Name`, Address) %>%
mutate(n = n()) %>%
filter(n > 1) %>%
arrange(`Project Name`, `Site Name`, Address) %>%
view()
# ------- DATA FILTER #5 ------- Small edits/checks
#Filter by InServiceDate - select only records in this vintage year or earlier
WSHFC_cleaned <- WSHFC_cleaned %>%
filter(`First Credit Year or C of O's` <= vintage_year)
#Consolidate SRO and STUDIO into one column
WSHFC_cleaned$STUDIO = WSHFC_cleaned$SRO + WSHFC_cleaned$STUDIO
## 4) clean up field names --------------------------------------------------------------------
#rename columns and add empty columns for data we dont have
WSHFC_cleaned <- WSHFC_cleaned %>%
mutate(DataSource = as.character(NA),
ami_25 = as.numeric("0"),
ami_75 = as.numeric("0"),
ami_85 = as.numeric("0"),
ami_90 = as.numeric("0"),
ami_100 = as.numeric("0"),
ami_120 = as.numeric("0"),
market_rate = as.numeric("0"),
manager_unit = as.numeric("0"),
confidentiality = as.character(NA),
policy = as.character(NA),
tenure = as.character(NA)) %>%
rename(project_id = `ProjectKey`,
project_name = `Project Name`,
property_id = `SiteKey`,
property_name = `Site Name`,
property_owner = `Contractor/Owner Org`,
manager = `Property Management Org`,
city = `City`,
total_units = `Total Project Units`,
total_restricted_units = `Income & Rent Restricted Units`,
in_service_date = `First Credit Year or C of O's`,
ami_20 = `20%`,
ami_30 = `30%`,
ami_35 = `35%`,
ami_40 = `40%`,
ami_45 = `45%`,
ami_50 = `50%`,
ami_60 = `60%`,
ami_65 = `65%`,
ami_70 = `70%`,
ami_80 = `80%`,
bedroom_0 = `STUDIO`,
bedroom_1 = `1 BR`,
bedroom_2 = `2 BR`,
bedroom_3 = `3 BR`,
bedroom_4 = `4 BR`,
bedroom_5 = `5 BR`,
bedroom_unknown = `Unknown`,
bed_count = `GROUP HOME/BED`,
home = `Number of HOME Units`,
HOMEcity = `HOME City`,
HOMEcounty = `HOME County`,
HOMEstate = `HOME State`,
funding_sources = `Funder`,
expiration_date = `Project Expiration Date`,
large_household = `Large Household (4+ pp)`,
site_type = `Site Type`,
senior = `Elderly`,
disabled = `Persons with Disabilities`,
reported_address = `Address`,
county = `County`,
farmworker = `Farmworker`,
homeless = `Homeless`,
transitional = `Transitional`,
data_source = `DataSource`,
veterans = `Veterans`,
zip = `Zip`)
#select only necessary columns and arrange columns
WSHFC_cleaned <- select_and_arrange_columns_function(WSHFC_cleaned)
WSHFC_cleaned$data_source = "WSHFC"
WSHFC_cleaned$reported_address[WSHFC_cleaned$reported_address == '1724 E. 44th'] <- '1724 E 44th Street'
WSHFC_cleaned$reported_address[WSHFC_cleaned$reported_address == '9225 Bayshore Drive NW'] <- '9225 Bay Shore Dr NW'
WSHFC_cleaned$reported_address[WSHFC_cleaned$reported_address == '9239 Bayshore Dr NW'] <- '9239 Bay Shore Dr NW'
# Clean address field for matching
# WSHFC_cleaned$full_address <- str_c(WSHFC_cleaned$reported_address,', ',WSHFC_cleaned$city,', WA, ',WSHFC_cleaned$zip)
# WSHFC_cleaned_test <- add_cleaned_addresses(WSHFC_cleaned)
#
# str(WSHFC_cleaned)
## 5) save file --------------------------------------------------------------------
#save cleaned file
write_csv(WSHFC_cleaned, paste0(WSHFC_path, WSHFC_clean_file))
library(tidyverse)
library(tidyr)
library(readxl)
library(data.table)
library(magrittr)
library(stringr)
library(dplyr)
library(odbc)
library(DBI)
remotes::install_github("slu-openGIS/postmastr")
elmer_connection <- dbConnect(odbc::odbc(),
driver = "SQL Server",
server = "AWS-PROD-SQL\\Sockeye",
database = "Elmer",
trusted_connection = "yes")
WSHFC_path <- "J:/Projects/IncomeRestrictedHsgDB/2022 vintage/Data/WSHFC/WSHFC_2022_cleaned.csv"
#export_4review_path <- "C:/Users/eclute/OneDrive - Puget Sound Regional Council/Documents/GitHub/irhd/Export4review.csv"
#HASCO_updates_path <- "J:/Projects/IncomeRestrictedHsgDB/2022 vintage/Review Files - Received/PSRC_2022_IRHD_Snohomish_minor updates.csv"
#THA_updates_path <- "J:/Projects/IncomeRestrictedHsgDB/2022 vintage/Review Files - Received/PSRC_2022_IRHD_Pierce_THA_minor updates.csv"
#KC_path <- "J:/Projects/IncomeRestrictedHsgDB/2022 vintage/Review Files - Received/King County Income-restricted Housing Database 2022.csv"
address_script <- "C:/Users/eclute/GitHub/irhd/address_match.R"
source(address_script)
`%not_in%` <- Negate(`%in%`)
vintage_year <- 2022
last_vintage <- vintage_year - 1
sql_import <- paste('irhd.properties')
sql_export <- paste('exec irhd.merge_irhd_properties', vintage_year)
# functions ---
# BY COUNTY
summary_county <- function(df){
new_IRHD_county <- df %>%
group_by(county) %>%
summarize("unit count" = sum(na.omit(total_restricted_units)))
# add total column
new_IRHD_county <- new_IRHD_county %>%
bind_rows(summarise(., across(where(is.numeric), sum),
across(where(is.character), ~'Total')))
#transpose
new_IRHD_county <- transpose(new_IRHD_county, keep.names = 'county')
#fix column names
colnames(new_IRHD_county) <- new_IRHD_county[1,]
new_IRHD_county <- new_IRHD_county[-1, ]
new_IRHD_county %<>% rename(!!paste(vintage_year, "new units") := "county")
}
# BY UNIT SIZE
summary_county_bedrooms <- function(df){
IRHD_county_bedrooms <- df %>%
group_by(county) %>%
summarize(`studio and one bedrooms` = sum(na.omit(bedroom_0 + bedroom_1)),`two and three bedrooms` = sum(na.omit(bedroom_2 + bedroom_3)),`four bedrooms and more` = sum(na.omit(bedroom_4 + bedroom_5)),`Unknown Size` = sum(na.omit(bedroom_Unknown)))
# add total column
IRHD_county_bedrooms <- IRHD_county_bedrooms %>%
bind_rows(summarise(., across(where(is.numeric), sum),
across(where(is.character), ~'Total')))
# add total row
IRHD_county_bedrooms %<>% mutate(total=rowSums(select_if(., is.numeric)))
#transpose
IRHD_county_bedrooms <- transpose(IRHD_county_bedrooms, keep.names = 'county')
#fix column names
colnames(IRHD_county_bedrooms) <- IRHD_county_bedrooms[1,]
IRHD_county_bedrooms <- IRHD_county_bedrooms[-1, ]
IRHD_county_bedrooms %<>% rename("unit_size" = "county")
}
# BY AMI LIMIT
summary_county_ami <- function(df){
IRHD_county_ami <- df %>%
group_by(county) %>%
summarize(`less than 30` = sum(na.omit(ami_20 + ami_25 + ami_30)),`31 to 50` = sum(na.omit(ami_35 + ami_40 + ami_45 +ami_50)),`51 to 80` = sum(na.omit(ami_60 + ami_65 + ami_70 + ami_75 + ami_80)),`81 to 100` = sum(na.omit(ami_85 + ami_90 + ami_100)),`100 plus` = sum(na.omit(ami_120)),`unknown AMI` = sum(na.omit(ami_unknown)))
# add total column
IRHD_county_ami <- IRHD_county_ami %>%
bind_rows(summarise(., across(where(is.numeric), sum),
across(where(is.character), ~'Total')))
# add total row
IRHD_county_ami %<>% mutate(total=rowSums(select_if(., is.numeric)))
#transpose
IRHD_county_ami <- transpose(IRHD_county_ami, keep.names = 'county')
#fix column names
colnames(IRHD_county_ami) <- IRHD_county_ami[1,]
IRHD_county_ami <- IRHD_county_ami[-1, ]
IRHD_county_ami %<>% rename("ami_limits" = "county")
}
## 1) load data -------------------------
# load last vintage from Elmer
IRHD_raw <- dbReadTable(elmer_connection, SQL(sql_import))
# borrow datatype characterization from IRHD to apply to identical columns in WSHFC data
# irhd_colClasses = sapply(IRHD_raw, class)
# names(irhd_colClasses) <- colnames(IRHD_raw)
# WSHFC_cols = colnames(read.csv(WSHFC_path, nrows=1))
# wshfc_colClasses <- irhd_colClasses %>% .[names(.) %in% WSHFC_cols]
# load cleaned WSHFC data that has portfolios as of end of 2022; apply datatypes to match
# WSHFC_raw <- fread(WSHFC_path, colClasses=wshfc_colClasses)
WSHFC_raw <- fread(WSHFC_path)
# load cleaned KC data that has portfolios as of end of 2022
# KC_raw <- fread(KC_path)
# load cleaned HASCO & THA data - only keep fields where we have new data (in the "Corrected" column)
# HASCO_raw <- fread(HASCO_updates_path)
# HASCO <- HASCO_raw %>%
#   drop_na(Corrected)
#
# THA_raw <- fread(THA_updates_path)
# THA <- THA_raw %>%
#   drop_na(Corrected)
## 2) clean up data -------------------------
# IRHD ---
IRHD_raw <- IRHD_raw %>% filter(data_year == last_vintage)
IRHD <- IRHD_raw %>% filter(!(county == "King"))  # King county handled separately
# Remove unneeded fields
IRHD %<>% select(-c(created_at,updated_at,sro,shape))
IRHD$property_id <- as.integer(IRHD$property_id)
# King County finalized data ---
# KC <- KC_raw
# KC$county <- "King"
# KC %<>% filter(KC$in_service_date <= vintage_year | is.na(KC$in_service_date))
# Remove fields we don't need
##(Policy field is blank, data currently stored in "FundingSource" - This may change!! Watch next year)
# KC %<>% select(-c(unique_linking_ID,HITS_survey,GeoCode_Street,GeoCode_City,ProjectType,Policy))
# Rename fields to match IRHD
# KC <- KC %>%
#   rename("data_source" = "DataSourceName",
#          "bed_count" = "GroupHomeOrBed",
#          "zip" = "GeoCode_Zip",
#          "full_address" = "address_standardized",
#          "expiration_date" = "ExpirationYear",
#          "property_owner" = "ProjectSponsor",
#          "manager" = "ContactName",
#          "site_type" = "PopulationServed",
#          "funding_sources" = "Funder",
#          "HOME" = "HOMEUnits",
#          "policy" = "FundingSource")
#
# KC$cleaned_address <- str_c(KC$full_address,', ',KC$city,', WA, ',KC$zip)
# Identify and remove duplicated working_id value
# dups <- filter(KC, working_id == "SH_5215")
# KC[1222,1]<-"SH_7234"
# rm(dups)
## 3) clean up some variables in WSHFC before joining -------------------------
## 4) Locate records in WSHFC_raw not in IRHD (likely new records/properties) -------------------------
newWSHFC <- anti_join(WSHFC_raw, IRHD, by = "property_id")
## 5) Locate records in IRHD not in WSHFC (No longer in WSHFC data. Will need to be verified (did they go offline, etc?)) -------------------------
nomatchIRHD <- anti_join(IRHD, WSHFC_raw, by = "property_id")
nomatchIRHD <- nomatchIRHD %>% drop_na(property_id)
## 6) Identify matched records in IRHD and WSHFC -------------------------
# Pivot the IRHD data to make it long and thin
long_IRHD <- IRHD %>%
pivot_longer(c('project_id',
'project_name',
'property_name',
'property_owner',
'manager',
'in_service_date',
'expiration_date',
'cleaned_address',
'county',
'total_units',
'total_restricted_units',
'ami_20','ami_25','ami_30','ami_35','ami_40','ami_45','ami_50','ami_60','ami_65','ami_70','ami_75','ami_80','ami_85','ami_90','ami_100',
'market_rate',
'manager_unit',
'bedroom_0','bedroom_1','bedroom_2','bedroom_3','bedroom_4','bedroom_5','bedroom_unknown',
'bed_count',
'site_type',
'HOMEcity',
'HOMEcounty',
'HOMEstate',
'confidentiality',
'policy',
'senior',
'disabled',
'homeless',
'transitional',
'veterans',
'funding_sources',
'tenure'),
names_to='variable_class',
values_to='variable_value',
values_transform = list(variable_value=as.character))
# Remove some fields that we don't need here
long_IRHD %<>% select(c(property_id,variable_class,variable_value))
# Pivot the mocked-up data to make it long and thin
long_WSHFC <- WSHFC_raw %>%
pivot_longer(c('project_id',
'project_name',
'property_name',
'property_owner',
'manager',
'in_service_date',
'expiration_date',
'cleaned_address',
'county',
'total_units',
'total_restricted_units',
'ami_20','ami_25','ami_30','ami_35','ami_40','ami_45','ami_50','ami_60','ami_65','ami_70','ami_75','ami_80','ami_85','ami_90','ami_100',
'market_rate',
'manager_unit',
'bedroom_0','bedroom_1','bedroom_2','bedroom_3','bedroom_4','bedroom_5','bedroom_unknown',
'bed_count',
'site_type',
'HOMEcity',
'HOMEcounty',
'HOMEstate',
'confidentiality',
'policy',
'senior',
'disabled',
'homeless',
'transitional',
'veterans',
'funding_sources',
'tenure'),
names_to='variable_class',
values_to='variable_value',
values_transform = list(variable_value=as.character))
