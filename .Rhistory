server = "AWS-PROD-SQL\\Sockeye",
database = "Elmer",
trusted_connection = "yes")
review_after_join_housingauthorities <- "./Export4review-housingauthorities.csv" # Export for review after WSHFC-IRHD join. Help understanding why property data are changing
review_after_join_wshfc <- "./Export4review-wshfc.csv" # Export for review after WSHFC-IRHD join. Help understanding why property data are missing, different, etc
final_review_housingauthorities <- "./final_review_housingauthorities.xlsx" # Export final dataset for review. Ask housing authorities to flag errors, add new properties, remove out-of-service properties, etc
#HASCO_updates_path <- ""
#THA_updates_path <- ""
address_func <- "./address_match.R"
irhd_func <- "./irhd_cleaning_func.R"
wshfc_clean_script <- "./clean_2022_WSHFC_data.R"
kc_clean_script <- "./clean_2022_KC_data.R"
source(address_func)
source(irhd_func)
`%not_in%` <- Negate(`%in%`)
vintage_year <- 2022
last_vintage <- vintage_year - 1
sql_import <- paste('irhd.properties')
sql_export <- paste('exec irhd.merge_irhd_properties', vintage_year)
## 1) load data -------------------------
# load all IRHD records from Elmer
IRHD_raw <- dbReadTable(elmer_connection, SQL(sql_import))
# load cleaned WSHFC data
source(wshfc_clean_script)
# load cleaned data from data partners
#source(kc_clean_script)
# Only keep fields where we have new data (in the "Corrected" column)
# HASCO_raw <- fread(HASCO_updates_path)
# HASCO <- HASCO_raw %>%
#   drop_na(Corrected)
#
# THA_raw <- fread(THA_updates_path)
# THA <- THA_raw %>%
#   drop_na(Corrected)
## 2) Final tweaks -------------------------
IRHD_raw <- IRHD_raw %>% filter(data_year == last_vintage)
IRHD <- IRHD_raw %>% filter(!(county == "King")) # King county handled separately
IRHD %<>% select(-c(created_at,updated_at,sro,shape,irhd_property_id)) # Remove unneeded fields
## 3) Locate records in WSHFC not in IRHD (likely new records/properties) -------------------------
new_wshfc <- anti_join(WSHFC_cleaned, IRHD, by = "property_id")
## 4) Locate records in IRHD not in WSHFC_cleaned (No longer in WSHFC data. Will need to be verified (did they go offline, etc?)) -------------------------
no_match_irhd <- anti_join(IRHD, WSHFC_cleaned, by = "property_id")
no_match_irhd <- no_match_irhd %>% drop_na(property_id)
write.csv(no_match_irhd, review_after_join_wshfc, row.names=FALSE)
irhd_func <- "./irhd_cleaning_func.R"
source(irhd_func)
source(irhd_func)
source(irhd_func)
View(identify_changes_IRHD)
identify_changes_irhd(IRHD, WSHFC_cleaned)
# TITLE: Reconcile IRHD and new data
# GEOGRAPHIES: King, Snohomish, Pierce, Kitsap
# DATA SOURCE: WSHFC, HASCO, THA, King County, EHA, PCHA, BHA
# DATE MODIFIED: 02.09.2024
# AUTHOR: Eric Clute
## assumptions -------------------------
library(tidyverse)
library(tidyr)
library(readxl)
library(data.table)
library(magrittr)
library(stringr)
library(dplyr)
library(odbc)
library(DBI)
library(openxlsx)
setwd("C:/Users/eclute/GitHub/irhd")
remotes::install_github("slu-openGIS/postmastr")
elmer_connection <- dbConnect(odbc::odbc(),
driver = "SQL Server",
server = "AWS-PROD-SQL\\Sockeye",
database = "Elmer",
trusted_connection = "yes")
review_after_join_housingauthorities <- "./Export4review-housingauthorities.csv" # Export for review after WSHFC-IRHD join. Help understanding why property data are changing
review_after_join_wshfc <- "./Export4review-wshfc.csv" # Export for review after WSHFC-IRHD join. Help understanding why property data are missing, different, etc
final_review_housingauthorities <- "./final_review_housingauthorities.xlsx" # Export final dataset for review. Ask housing authorities to flag errors, add new properties, remove out-of-service properties, etc
#HASCO_updates_path <- ""
#THA_updates_path <- ""
address_func <- "./address_match.R"
irhd_func <- "./irhd_cleaning_func.R"
wshfc_clean_script <- "./clean_2022_WSHFC_data.R"
kc_clean_script <- "./clean_2022_KC_data.R"
source(address_func)
source(irhd_func)
`%not_in%` <- Negate(`%in%`)
vintage_year <- 2022
last_vintage <- vintage_year - 1
sql_import <- paste('irhd.properties')
sql_export <- paste('exec irhd.merge_irhd_properties', vintage_year)
## 1) load data -------------------------
# load all IRHD records from Elmer
IRHD_raw <- dbReadTable(elmer_connection, SQL(sql_import))
# load cleaned WSHFC data
source(wshfc_clean_script)
# load cleaned data from data partners
#source(kc_clean_script)
# Only keep fields where we have new data (in the "Corrected" column)
# HASCO_raw <- fread(HASCO_updates_path)
# HASCO <- HASCO_raw %>%
#   drop_na(Corrected)
#
# THA_raw <- fread(THA_updates_path)
# THA <- THA_raw %>%
#   drop_na(Corrected)
## 2) Final tweaks -------------------------
IRHD_raw <- IRHD_raw %>% filter(data_year == last_vintage)
IRHD <- IRHD_raw %>% filter(!(county == "King")) # King county handled separately
IRHD %<>% select(-c(created_at,updated_at,sro,shape,irhd_property_id)) # Remove unneeded fields
## 3) Locate records in WSHFC not in IRHD (likely new records/properties) -------------------------
new_wshfc <- anti_join(WSHFC_cleaned, IRHD, by = "property_id")
## 4) Locate records in IRHD not in WSHFC_cleaned (No longer in WSHFC data. Will need to be verified (did they go offline, etc?)) -------------------------
no_match_irhd <- anti_join(IRHD, WSHFC_cleaned, by = "property_id")
no_match_irhd <- no_match_irhd %>% drop_na(property_id)
write.csv(no_match_irhd, review_after_join_wshfc, row.names=FALSE)
identify_changes_irhd(IRHD, WSHFC_cleaned)
identify_changes_irhd(IRHD, WSHFC_cleaned)
source(irhd_func)
identify_changes_irhd(IRHD, WSHFC_cleaned)
source(irhd_func)
identify_changes_irhd(IRHD, WSHFC_cleaned)
source(irhd_func)
identify_changes_irhd(IRHD, WSHFC_cleaned)
source(irhd_func)
identify_changes_irhd(IRHD, WSHFC_cleaned)
source(irhd_func)
identify_changes_irhd(IRHD)
source(irhd_func)
identify_changes_irhd(IRHD)
source(irhd_func)
identify_changes_irhd(IRHD)
source(irhd_func)
identify_changes_irhd(IRHD, WSHFC_cleaned)
source(irhd_func)
identify_changes_irhd(IRHD, WSHFC_cleaned)
source(irhd_func)
identify_changes_irhd(IRHD)
source(irhd_func)
identify_changes_irhd(IRHD)
identify_changes_irhd(IRHD)
library(tidyverse)
library(tidyr)
library(readxl)
library(data.table)
library(magrittr)
library(stringr)
library(dplyr)
library(odbc)
library(DBI)
library(openxlsx)
setwd("C:/Users/eclute/GitHub/irhd")
remotes::install_github("slu-openGIS/postmastr")
elmer_connection <- dbConnect(odbc::odbc(),
driver = "SQL Server",
server = "AWS-PROD-SQL\\Sockeye",
database = "Elmer",
trusted_connection = "yes")
review_after_join_housingauthorities <- "./Export4review-housingauthorities.csv" # Export for review after WSHFC-IRHD join. Help understanding why property data are changing
review_after_join_wshfc <- "./Export4review-wshfc.csv" # Export for review after WSHFC-IRHD join. Help understanding why property data are missing, different, etc
final_review_housingauthorities <- "./final_review_housingauthorities.xlsx" # Export final dataset for review. Ask housing authorities to flag errors, add new properties, remove out-of-service properties, etc
#HASCO_updates_path <- ""
#THA_updates_path <- ""
address_func <- "./address_match.R"
irhd_func <- "./irhd_cleaning_func.R"
wshfc_clean_script <- "./clean_2022_WSHFC_data.R"
kc_clean_script <- "./clean_2022_KC_data.R"
source(address_func)
source(irhd_func)
`%not_in%` <- Negate(`%in%`)
vintage_year <- 2022
last_vintage <- vintage_year - 1
sql_import <- paste('irhd.properties')
sql_export <- paste('exec irhd.merge_irhd_properties', vintage_year)
## 1) load data -------------------------
# load all IRHD records from Elmer
IRHD_raw <- dbReadTable(elmer_connection, SQL(sql_import))
# load cleaned WSHFC data
source(wshfc_clean_script)
# load cleaned data from data partners
#source(kc_clean_script)
# Only keep fields where we have new data (in the "Corrected" column)
# HASCO_raw <- fread(HASCO_updates_path)
# HASCO <- HASCO_raw %>%
#   drop_na(Corrected)
#
# THA_raw <- fread(THA_updates_path)
# THA <- THA_raw %>%
#   drop_na(Corrected)
## 2) Final tweaks -------------------------
IRHD_raw <- IRHD_raw %>% filter(data_year == last_vintage)
IRHD <- IRHD_raw %>% filter(!(county == "King")) # King county handled separately
IRHD %<>% select(-c(created_at,updated_at,sro,shape,irhd_property_id)) # Remove unneeded fields
## 3) Locate records in WSHFC not in IRHD (likely new records/properties) -------------------------
new_wshfc <- anti_join(WSHFC_cleaned, IRHD, by = "property_id")
## 4) Locate records in IRHD not in WSHFC_cleaned (No longer in WSHFC data. Will need to be verified (did they go offline, etc?)) -------------------------
no_match_irhd <- anti_join(IRHD, WSHFC_cleaned, by = "property_id")
no_match_irhd <- no_match_irhd %>% drop_na(property_id)
write.csv(no_match_irhd, review_after_join_wshfc, row.names=FALSE)
## 5) Identify matched records in IRHD and WSHFC_cleaned -------------------------
identify_changes_irhd(IRHD)
source(irhd_func)
identify_changes_irhd(IRHD)
# Pivot the IRHD data to make it long and thin
long_IRHD <- df %>%
pivot_longer(c('project_id',
'project_name',
'property_name',
'property_owner',
'manager',
'in_service_date',
'expiration_date',
'cleaned_address',
'county',
'total_units',
'total_restricted_units',
'ami_20','ami_25','ami_30','ami_35','ami_40','ami_45','ami_50','ami_60','ami_65','ami_70','ami_75','ami_80','ami_85','ami_90','ami_100',
'market_rate',
'manager_unit',
'bedroom_0','bedroom_1','bedroom_2','bedroom_3','bedroom_4','bedroom_5','bedroom_unknown',
'bed_count',
'site_type',
'HOMEcity',
'HOMEcounty',
'HOMEstate',
'confidentiality',
'policy',
'senior',
'disabled',
'homeless',
'transitional',
'veterans',
'funding_sources',
'tenure'),
names_to='variable_class',
values_to='variable_value',
values_transform = list(variable_value=as.character))
# Pivot the IRHD data to make it long and thin
long_IRHD <- IRHD %>%
pivot_longer(c('project_id',
'project_name',
'property_name',
'property_owner',
'manager',
'in_service_date',
'expiration_date',
'cleaned_address',
'county',
'total_units',
'total_restricted_units',
'ami_20','ami_25','ami_30','ami_35','ami_40','ami_45','ami_50','ami_60','ami_65','ami_70','ami_75','ami_80','ami_85','ami_90','ami_100',
'market_rate',
'manager_unit',
'bedroom_0','bedroom_1','bedroom_2','bedroom_3','bedroom_4','bedroom_5','bedroom_unknown',
'bed_count',
'site_type',
'HOMEcity',
'HOMEcounty',
'HOMEstate',
'confidentiality',
'policy',
'senior',
'disabled',
'homeless',
'transitional',
'veterans',
'funding_sources',
'tenure'),
names_to='variable_class',
values_to='variable_value',
values_transform = list(variable_value=as.character))
rm(long_IRHD)
source(irhd_func)
identify_changes_irhd(IRHD)
# Pivot the IRHD data to make it long and thin
long_IRHD <- df1 %>%
pivot_longer(c('project_id',
'project_name',
'property_name',
'property_owner',
'manager',
'in_service_date',
'expiration_date',
'cleaned_address',
'county',
'total_units',
'total_restricted_units',
'ami_20','ami_25','ami_30','ami_35','ami_40','ami_45','ami_50','ami_60','ami_65','ami_70','ami_75','ami_80','ami_85','ami_90','ami_100',
'market_rate',
'manager_unit',
'bedroom_0','bedroom_1','bedroom_2','bedroom_3','bedroom_4','bedroom_5','bedroom_unknown',
'bed_count',
'site_type',
'HOMEcity',
'HOMEcounty',
'HOMEstate',
'confidentiality',
'policy',
'senior',
'disabled',
'homeless',
'transitional',
'veterans',
'funding_sources',
'tenure'),
names_to='variable_class',
values_to='variable_value',
values_transform = list(variable_value=as.character))
source(irhd_func)
rectify <- identify_changes_irhd(IRHD)
rectify <- identify_changes_irhd(IRHD, WSHFC_cleaned)
library(tidyverse)
library(tidyr)
library(readxl)
library(data.table)
library(magrittr)
library(stringr)
library(dplyr)
library(odbc)
library(DBI)
library(openxlsx)
setwd("C:/Users/eclute/GitHub/irhd")
remotes::install_github("slu-openGIS/postmastr")
elmer_connection <- dbConnect(odbc::odbc(),
driver = "SQL Server",
server = "AWS-PROD-SQL\\Sockeye",
database = "Elmer",
trusted_connection = "yes")
review_after_join_housingauthorities <- "./Export4review-housingauthorities.csv" # Export for review after WSHFC-IRHD join. Help understanding why property data are changing
review_after_join_wshfc <- "./Export4review-wshfc.csv" # Export for review after WSHFC-IRHD join. Help understanding why property data are missing, different, etc
final_review_housingauthorities <- "./final_review_housingauthorities.xlsx" # Export final dataset for review. Ask housing authorities to flag errors, add new properties, remove out-of-service properties, etc
#HASCO_updates_path <- ""
#THA_updates_path <- ""
address_func <- "./address_match.R"
irhd_func <- "./irhd_cleaning_func.R"
wshfc_clean_script <- "./clean_2022_WSHFC_data.R"
kc_clean_script <- "./clean_2022_KC_data.R"
source(address_func)
source(irhd_func)
`%not_in%` <- Negate(`%in%`)
vintage_year <- 2022
last_vintage <- vintage_year - 1
sql_import <- paste('irhd.properties')
sql_export <- paste('exec irhd.merge_irhd_properties', vintage_year)
## 1) load data -------------------------
# load all IRHD records from Elmer
IRHD_raw <- dbReadTable(elmer_connection, SQL(sql_import))
# load cleaned WSHFC data
source(wshfc_clean_script)
# load cleaned data from data partners
#source(kc_clean_script)
# Only keep fields where we have new data (in the "Corrected" column)
# HASCO_raw <- fread(HASCO_updates_path)
# HASCO <- HASCO_raw %>%
#   drop_na(Corrected)
#
# THA_raw <- fread(THA_updates_path)
# THA <- THA_raw %>%
#   drop_na(Corrected)
## 2) Final tweaks -------------------------
IRHD_raw <- IRHD_raw %>% filter(data_year == last_vintage)
IRHD <- IRHD_raw %>% filter(!(county == "King")) # King county handled separately
IRHD %<>% select(-c(created_at,updated_at,sro,shape,irhd_property_id)) # Remove unneeded fields
## 3) Locate records in WSHFC not in IRHD (likely new records/properties) -------------------------
new_wshfc <- anti_join(WSHFC_cleaned, IRHD, by = "property_id")
## 4) Locate records in IRHD not in WSHFC_cleaned (No longer in WSHFC data. Will need to be verified (did they go offline, etc?)) -------------------------
no_match_irhd <- anti_join(IRHD, WSHFC_cleaned, by = "property_id")
no_match_irhd <- no_match_irhd %>% drop_na(property_id)
write.csv(no_match_irhd, review_after_join_wshfc, row.names=FALSE)
long_IRHD <- IRHD %>%
pivot_longer(c('project_id',
'project_name',
'property_name',
'property_owner',
'manager',
'in_service_date',
'expiration_date',
'cleaned_address',
'county',
'total_units',
'total_restricted_units',
'ami_20','ami_25','ami_30','ami_35','ami_40','ami_45','ami_50','ami_60','ami_65','ami_70','ami_75','ami_80','ami_85','ami_90','ami_100',
'market_rate',
'manager_unit',
'bedroom_0','bedroom_1','bedroom_2','bedroom_3','bedroom_4','bedroom_5','bedroom_unknown',
'bed_count',
'site_type',
'HOMEcity',
'HOMEcounty',
'HOMEstate',
'confidentiality',
'policy',
'senior',
'disabled',
'homeless',
'transitional',
'veterans',
'funding_sources',
'tenure'),
names_to='variable_class',
values_to='variable_value',
values_transform = list(variable_value=as.character))
# Remove some fields that we don't need here
long_IRHD %<>% select(c(property_id,variable_class,variable_value))
# Pivot the mocked-up data to make it long and thin
long_WSHFC <- WSHFC_cleaned %>%
pivot_longer(c('project_id',
'project_name',
'property_name',
'property_owner',
'manager',
'in_service_date',
'expiration_date',
'cleaned_address',
'county',
'total_units',
'total_restricted_units',
'ami_20','ami_25','ami_30','ami_35','ami_40','ami_45','ami_50','ami_60','ami_65','ami_70','ami_75','ami_80','ami_85','ami_90','ami_100',
'market_rate',
'manager_unit',
'bedroom_0','bedroom_1','bedroom_2','bedroom_3','bedroom_4','bedroom_5','bedroom_unknown',
'bed_count',
'site_type',
'HOMEcity',
'HOMEcounty',
'HOMEstate',
'confidentiality',
'policy',
'senior',
'disabled',
'homeless',
'transitional',
'veterans',
'funding_sources',
'tenure'),
names_to='variable_class',
values_to='variable_value',
values_transform = list(variable_value=as.character))
# Remove some fields that we don't need here
long_WSHFC %<>% select(c(property_id,variable_class,variable_value))
# Compare the two data sets in long form to identify values that have been changed
rectify <- long_IRHD %>%
inner_join(long_WSHFC, by=c('property_id', 'variable_class')) %>%
mutate("match" = ifelse(mapply(identical, variable_value.x, variable_value.y), "YES", "NO")) %>%
filter(match == "NO") %>%
drop_na(variable_value.y)
View(rectify)
View(rectify)
View(rectify)
source(irhd_func)
library(tidyverse)
library(tidyr)
library(readxl)
library(data.table)
library(magrittr)
library(stringr)
library(dplyr)
library(odbc)
library(DBI)
library(openxlsx)
setwd("C:/Users/eclute/GitHub/irhd")
remotes::install_github("slu-openGIS/postmastr")
elmer_connection <- dbConnect(odbc::odbc(),
driver = "SQL Server",
server = "AWS-PROD-SQL\\Sockeye",
database = "Elmer",
trusted_connection = "yes")
review_after_join_housingauthorities <- "./Export4review-housingauthorities.csv" # Export for review after WSHFC-IRHD join. Help understanding why property data are changing
review_after_join_wshfc <- "./Export4review-wshfc.csv" # Export for review after WSHFC-IRHD join. Help understanding why property data are missing, different, etc
final_review_housingauthorities <- "./final_review_housingauthorities.xlsx" # Export final dataset for review. Ask housing authorities to flag errors, add new properties, remove out-of-service properties, etc
#HASCO_updates_path <- ""
#THA_updates_path <- ""
address_func <- "./address_match.R"
irhd_func <- "./irhd_cleaning_func.R"
wshfc_clean_script <- "./clean_2022_WSHFC_data.R"
kc_clean_script <- "./clean_2022_KC_data.R"
source(address_func)
source(irhd_func)
`%not_in%` <- Negate(`%in%`)
vintage_year <- 2022
last_vintage <- vintage_year - 1
sql_import <- paste('irhd.properties')
sql_export <- paste('exec irhd.merge_irhd_properties', vintage_year)
## 1) load data -------------------------
# load all IRHD records from Elmer
IRHD_raw <- dbReadTable(elmer_connection, SQL(sql_import))
# load cleaned WSHFC data
source(wshfc_clean_script)
# load cleaned data from data partners
#source(kc_clean_script)
# Only keep fields where we have new data (in the "Corrected" column)
# HASCO_raw <- fread(HASCO_updates_path)
# HASCO <- HASCO_raw %>%
#   drop_na(Corrected)
#
# THA_raw <- fread(THA_updates_path)
# THA <- THA_raw %>%
#   drop_na(Corrected)
## 2) Final tweaks -------------------------
IRHD_raw <- IRHD_raw %>% filter(data_year == last_vintage)
IRHD <- IRHD_raw %>% filter(!(county == "King")) # King county handled separately
IRHD %<>% select(-c(created_at,updated_at,sro,shape,irhd_property_id)) # Remove unneeded fields
## 3) Locate records in WSHFC not in IRHD (likely new records/properties) -------------------------
new_wshfc <- anti_join(WSHFC_cleaned, IRHD, by = "property_id")
## 4) Locate records in IRHD not in WSHFC_cleaned (No longer in WSHFC data. Will need to be verified (did they go offline, etc?)) -------------------------
no_match_irhd <- anti_join(IRHD, WSHFC_cleaned, by = "property_id")
no_match_irhd <- no_match_irhd %>% drop_na(property_id)
write.csv(no_match_irhd, review_after_join_wshfc, row.names=FALSE)
## 5) Identify changes - IRHD and WSHFC_cleaned. Create long-form for easy comparison -------------------------
rectify <- identify_changes_irhd(IRHD, WSHFC_cleaned)
View(rectify)
source(irhd_func)
rectify <- identify_changes_irhd(IRHD, WSHFC_cleaned)
View(rectify)
