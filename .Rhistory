filter(!(`Project Name` == "Maternity Shelter (Youth Emergency Shelter (YES) North)" & `Site Name` == "Youth Emergency Shelter (YES) North" & `50%` == 8)) #remove this record, keep record with deeper affordability
#check to see if any duplicates remaining - should be 0
WSHFC_cleaned %>%
distinct() %>%
group_by(`Site Name`, Address) %>%
mutate(n = n()) %>%
filter(n > 1) %>%
arrange(`Project Name`, `Site Name`, Address) %>%
view()
# ------- DATA FILTER #5 ------- Small edits/checks
#Filter by InServiceDate - select only records in this vintage year or earlier
WSHFC_cleaned <- WSHFC_cleaned %>%
filter(`First Credit Year or C of O's` <= vintage_year)
#Consolidate SRO and STUDIO into one column
WSHFC_cleaned$STUDIO = WSHFC_cleaned$SRO + WSHFC_cleaned$STUDIO
## 4) clean up field names --------------------------------------------------------------------
#rename columns and add empty columns for data we dont have
WSHFC_cleaned <- WSHFC_cleaned %>%
mutate(DataSource = as.character(NA),
ami_25 = as.numeric("0"),
ami_75 = as.numeric("0"),
ami_85 = as.numeric("0"),
ami_90 = as.numeric("0"),
ami_100 = as.numeric("0"),
ami_120 = as.numeric("0"),
market_rate = as.numeric("0"),
manager_unit = as.numeric("0"),
confidentiality = as.character(NA),
policy = as.character(NA),
tenure = as.character(NA)) %>%
rename(project_id = `ProjectKey`,
project_name = `Project Name`,
property_id = `SiteKey`,
property_name = `Site Name`,
property_owner = `Contractor/Owner Org`,
manager = `Property Management Org`,
city = `City`,
total_units = `Total Project Units`,
total_restricted_units = `Income & Rent Restricted Units`,
in_service_date = `First Credit Year or C of O's`,
ami_20 = `20%`,
ami_30 = `30%`,
ami_35 = `35%`,
ami_40 = `40%`,
ami_45 = `45%`,
ami_50 = `50%`,
ami_60 = `60%`,
ami_65 = `65%`,
ami_70 = `70%`,
ami_80 = `80%`,
bedroom_0 = `STUDIO`,
bedroom_1 = `1 BR`,
bedroom_2 = `2 BR`,
bedroom_3 = `3 BR`,
bedroom_4 = `4 BR`,
bedroom_5 = `5 BR`,
bedroom_unknown = `Unknown`,
bed_count = `GROUP HOME/BED`,
home = `Number of HOME Units`,
HOMEcity = `HOME City`,
HOMEcounty = `HOME County`,
HOMEstate = `HOME State`,
funding_sources = `Funder`,
expiration_date = `Project Expiration Date`,
large_household = `Large Household (4+ pp)`,
site_type = `Site Type`,
senior = `Elderly`,
disabled = `Persons with Disabilities`,
reported_address = `Address`,
county = `County`,
farmworker = `Farmworker`,
homeless = `Homeless`,
transitional = `Transitional`,
data_source = `DataSource`,
veterans = `Veterans`,
zip = `Zip`)
#select only necessary columns and arrange columns
WSHFC_cleaned <- select_and_arrange_columns_function(WSHFC_cleaned)
#set DataSource field
WSHFC_cleaned$data_source = "WSHFC"
WSHFC_cleaned$reported_address[WSHFC_cleaned$reported_address == '1724 E. 44th'] <- '1724 E 44th Street'
WSHFC_cleaned$reported_address[WSHFC_cleaned$reported_address == '9225 Bayshore Drive NW'] <- '9225 Bay Shore Dr NW'
WSHFC_cleaned$reported_address[WSHFC_cleaned$reported_address == '9239 Bayshore Dr NW'] <- '9239 Bay Shore Dr NW'
# Clean address field for matching
# WSHFC_cleaned$full_address <- str_c(WSHFC_cleaned$reported_address,', ',WSHFC_cleaned$city,', WA, ',WSHFC_cleaned$zip)
# WSHFC_cleaned_test <- add_cleaned_addresses(WSHFC_cleaned)
#
# str(WSHFC_cleaned)
## 5) save file --------------------------------------------------------------------
#save cleaned file
write_csv(WSHFC_cleaned, paste0(WSHFC_path, WSHFC_clean_file))
## assumptions -------------------------
library(tidyverse)
library(tidyr)
library(readxl)
library(data.table)
library(magrittr)
library(stringr)
library(dplyr)
library(odbc)
library(DBI)
remotes::install_github("slu-openGIS/postmastr")
elmer_connection <- dbConnect(odbc::odbc(),
driver = "SQL Server",
server = "AWS-PROD-SQL\\Sockeye",
database = "Elmer",
trusted_connection = "yes")
WSHFC_path <- "J:/Projects/IncomeRestrictedHsgDB/2022 vintage/Data/WSHFC/WSHFC_2022_cleaned.csv"
#export_4review_path <- "C:/Users/eclute/OneDrive - Puget Sound Regional Council/Documents/GitHub/irhd/Export4review.csv"
#HASCO_updates_path <- "J:/Projects/IncomeRestrictedHsgDB/2022 vintage/Review Files - Received/PSRC_2022_IRHD_Snohomish_minor updates.csv"
#THA_updates_path <- "J:/Projects/IncomeRestrictedHsgDB/2022 vintage/Review Files - Received/PSRC_2022_IRHD_Pierce_THA_minor updates.csv"
#KC_path <- "J:/Projects/IncomeRestrictedHsgDB/2022 vintage/Review Files - Received/King County Income-restricted Housing Database 2022.csv"
address_script <- "C:/Users/eclute/OneDrive - Puget Sound Regional Council/Documents/GitHub/irhd/address_match.R"
source(address_script)
`%not_in%` <- Negate(`%in%`)
vintage_year <- 2022
last_vintage <- vintage_year - 1
sql_import <- paste('irhd.properties')
sql_export <- paste('exec irhd.merge_irhd_properties', vintage_year)
# functions ---
# BY COUNTY
summary_county <- function(df){
new_IRHD_county <- df %>%
group_by(county) %>%
summarize("unit count" = sum(na.omit(total_restricted_units)))
# add total column
new_IRHD_county <- new_IRHD_county %>%
bind_rows(summarise(., across(where(is.numeric), sum),
across(where(is.character), ~'Total')))
#transpose
new_IRHD_county <- transpose(new_IRHD_county, keep.names = 'county')
#fix column names
colnames(new_IRHD_county) <- new_IRHD_county[1,]
new_IRHD_county <- new_IRHD_county[-1, ]
new_IRHD_county %<>% rename(!!paste(vintage_year, "new units") := "county")
}
# BY UNIT SIZE
summary_county_bedrooms <- function(df){
IRHD_county_bedrooms <- df %>%
group_by(county) %>%
summarize(`studio and one bedrooms` = sum(na.omit(bedroom_0 + bedroom_1)),`two and three bedrooms` = sum(na.omit(bedroom_2 + bedroom_3)),`four bedrooms and more` = sum(na.omit(bedroom_4 + bedroom_5)),`Unknown Size` = sum(na.omit(bedroom_Unknown)))
# add total column
IRHD_county_bedrooms <- IRHD_county_bedrooms %>%
bind_rows(summarise(., across(where(is.numeric), sum),
across(where(is.character), ~'Total')))
# add total row
IRHD_county_bedrooms %<>% mutate(total=rowSums(select_if(., is.numeric)))
#transpose
IRHD_county_bedrooms <- transpose(IRHD_county_bedrooms, keep.names = 'county')
#fix column names
colnames(IRHD_county_bedrooms) <- IRHD_county_bedrooms[1,]
IRHD_county_bedrooms <- IRHD_county_bedrooms[-1, ]
IRHD_county_bedrooms %<>% rename("unit_size" = "county")
}
# BY AMI LIMIT
summary_county_ami <- function(df){
IRHD_county_ami <- df %>%
group_by(county) %>%
summarize(`less than 30` = sum(na.omit(ami_20 + ami_25 + ami_30)),`31 to 50` = sum(na.omit(ami_35 + ami_40 + ami_45 +ami_50)),`51 to 80` = sum(na.omit(ami_60 + ami_65 + ami_70 + ami_75 + ami_80)),`81 to 100` = sum(na.omit(ami_85 + ami_90 + ami_100)),`100 plus` = sum(na.omit(ami_120)),`unknown AMI` = sum(na.omit(ami_unknown)))
# add total column
IRHD_county_ami <- IRHD_county_ami %>%
bind_rows(summarise(., across(where(is.numeric), sum),
across(where(is.character), ~'Total')))
# add total row
IRHD_county_ami %<>% mutate(total=rowSums(select_if(., is.numeric)))
#transpose
IRHD_county_ami <- transpose(IRHD_county_ami, keep.names = 'county')
#fix column names
colnames(IRHD_county_ami) <- IRHD_county_ami[1,]
IRHD_county_ami <- IRHD_county_ami[-1, ]
IRHD_county_ami %<>% rename("ami_limits" = "county")
}
## 1) load data -------------------------
# load last vintage from Elmer
IRHD_raw <- dbReadTable(elmer_connection, SQL(sql_import))
# borrow datatype characterization from IRHD to apply to identical columns in WSHFC data
# irhd_colClasses = sapply(IRHD_raw, class)
# names(irhd_colClasses) <- colnames(IRHD_raw)
# WSHFC_cols = colnames(read.csv(WSHFC_path, nrows=1))
# wshfc_colClasses <- irhd_colClasses %>% .[names(.) %in% WSHFC_cols]
# load cleaned WSHFC data that has portfolios as of end of 2022; apply datatypes to match
# WSHFC_raw <- fread(WSHFC_path, colClasses=wshfc_colClasses)
WSHFC_raw <- fread(WSHFC_path)
# load cleaned KC data that has portfolios as of end of 2022
# KC_raw <- fread(KC_path)
# load cleaned HASCO & THA data - only keep fields where we have new data (in the "Corrected" column)
# HASCO_raw <- fread(HASCO_updates_path)
# HASCO <- HASCO_raw %>%
#   drop_na(Corrected)
#
# THA_raw <- fread(THA_updates_path)
# THA <- THA_raw %>%
#   drop_na(Corrected)
## 2) clean up data -------------------------
# IRHD ---
IRHD_raw <- IRHD_raw %>% filter(data_year == last_vintage)
IRHD <- IRHD_raw %>% filter(!(county == "King"))  # King county handled separately
# Remove unneeded fields
IRHD %<>% select(-c(created_at,updated_at,sro,shape))
# King County finalized data ---
# KC <- KC_raw
# KC$county <- "King"
# KC %<>% filter(KC$in_service_date <= vintage_year | is.na(KC$in_service_date))
# Remove fields we don't need
##(Policy field is blank, data currently stored in "FundingSource" - This may change!! Watch next year)
# KC %<>% select(-c(unique_linking_ID,HITS_survey,GeoCode_Street,GeoCode_City,ProjectType,Policy))
# Rename fields to match IRHD
# KC <- KC %>%
#   rename("data_source" = "DataSourceName",
#          "bed_count" = "GroupHomeOrBed",
#          "zip" = "GeoCode_Zip",
#          "full_address" = "address_standardized",
#          "expiration_date" = "ExpirationYear",
#          "property_owner" = "ProjectSponsor",
#          "manager" = "ContactName",
#          "site_type" = "PopulationServed",
#          "funding_sources" = "Funder",
#          "HOME" = "HOMEUnits",
#          "policy" = "FundingSource")
#
# KC$cleaned.address <- str_c(KC$full_address,', ',KC$city,', WA, ',KC$zip)
# Identify and remove duplicated working_id value
# dups <- filter(KC, working_id == "SH_5215")
# KC[1222,1]<-"SH_7234"
# rm(dups)
## 3) clean up some variables in WSHFC before joining -------------------------
newWSHFC <- anti_join(WSHFC_raw, IRHD, by = "property_id")
str(WSHFC_raw)
class(WSHFC_raw$project_id) = "numeric"
newWSHFC <- anti_join(WSHFC_raw, IRHD, by = "property_id")
class(WSHFC_raw$property_id) = "numeric"
newWSHFC <- anti_join(WSHFC_raw, IRHD, by = "property_id")
install.packages("tidycensus")
install.packages("psrccensus")
install.packages(c("dbplyr", "evaluate", "htmltools", "httpuv", "httr2", "knitr", "leaflet", "lifecycle", "maps", "markdown", "plotly", "RcppEigen", "rlang", "rprojroot", "RSQLite", "stringi", "utf8", "waldo", "withr", "wk", "xfun", "XML"))
true
library(psrccensus)
library(openxlsx)
library(tidycensus)
library(tidyverse)
# years of interest (applies to all functions below)
years <- c(2019,2021)
create_mmh_owner_summary_table <- function(year) {
#---------------------Grab data from Census API------------------------
mmh_raw<-get_acs_recs(geography = 'county',
table.names = c('B25032'),
years = years,
counties = c("King", "Kitsap", "Pierce", "Snohomish"),
acs.type = 'acs1')
#---------------------Create custom groupings------------------------
# The next step is to create the appropriate grouping variable (using pipes for simplicity)
mmh_coded <- mmh_raw %>%
mutate(building_size=factor(case_when(grepl("_003$", variable) ~ "Single Family",
grepl("_004$|_005$|_006$", variable) ~ "2-4 units",
grepl("_007$|_008$", variable) ~ "5-19 units",
grepl("_009$|_010$", variable) ~ "20+ units",
grepl("_011$|_012$", variable) ~ "Mobile Home/Other",
TRUE ~ NA_character_),
levels=c("Single Family","2-4 units","5-19 units", "20+ units", "Mobile Home/Other"))) %>%
mutate(building_size_2=factor(case_when(grepl("_003$", variable) ~ "Single Family",
grepl("_004$|_005$|_006$|_007$|_008$", variable) ~ "2-19 units",
grepl("_009$|_010$", variable) ~ "20+ units",
grepl("_011$|_012$", variable) ~ "Mobile Home/Other",
TRUE ~ NA_character_),
levels=c("Single Family","2-19 units", "20+ units", "Mobile Home/Other")
))
#--------------------Aggregate data, incorporate 2-19 Unit group------------------------
# In this step, you create an aggregate, using the grouping you created in the last call.
mmh_agg_owner <- summarize(mmh_raw, estimate=sum(estimate, na.rm=TRUE), moe=moe_sum(moe=moe, estimate=estimate, na.rm=TRUE))
# In this step, you create an aggregate, using the first grouping you created in the last call.
mmh_agg_owner_01 <- mmh_coded %>%
group_by(across(c(name, year, building_size))) %>%
summarize(estimate=sum(estimate, na.rm=TRUE), moe=moe_sum(moe=moe, estimate=estimate, na.rm=TRUE))
# In this step, you create an aggregate, using the second grouping you created.
mmh_agg_owner_02 <- mmh_coded %>%
group_by(across(c(name, year, building_size_2))) %>%
summarize(estimate=sum(estimate, na.rm=TRUE), moe=moe_sum(moe=moe, estimate=estimate, na.rm=TRUE)) %>%
filter(building_size_2 == '2-19 units') %>%
rename(building_size = building_size_2)
df <- mmh_agg_owner_01 %>%
bind_rows(mmh_agg_owner_02)
}
all_owner_tables <- map(years, ~create_mmh_owner_summary_table(.x)) %>%
reduce(bind_rows)
mmh_owner <- all_owner_tables %>%
mutate(building_size = factor(building_size,
levels = c('Single Family', '2-4 units', '5-19 units', '2-19 units', '20+ units', 'Mobile Home/Other'))) %>%
arrange(year, name, building_size) %>%
filter(building_size != is.na(building_size))
rm(list = setdiff(ls(), c("mmh_owner", "create_mmh_owner_summary_table", "years")))
View(mmh_owner)
# years of interest (applies to all functions below)
years <- c(2019,2022)
all_owner_tables <- map(years, ~create_mmh_owner_summary_table(.x)) %>%
reduce(bind_rows)
mmh_owner <- all_owner_tables %>%
mutate(building_size = factor(building_size,
levels = c('Single Family', '2-4 units', '5-19 units', '2-19 units', '20+ units', 'Mobile Home/Other'))) %>%
arrange(year, name, building_size) %>%
filter(building_size != is.na(building_size))
rm(list = setdiff(ls(), c("mmh_owner", "create_mmh_owner_summary_table", "years")))
View(mmh_owner)
create_mmh_renter_summary_table <- function(year) {
#---------------------Grab data from Census API------------------------
mmh_raw<-get_acs_recs(geography = 'county',
table.names = c('B25032'),
years = year,
counties = c("King", "Kitsap", "Pierce", "Snohomish"),
acs.type = 'acs1')
#---------------------Create custom groupings------------------------
# The next step is to create the appropriate grouping variable (using pipes for simplicity)
mmh_coded <- mmh_raw %>%
mutate(building_size=factor(case_when(grepl("_014$", variable) ~ "Single Family",
grepl("_015$|_016$|_017$", variable) ~ "2-4 units",
grepl("_018$|_019$", variable) ~ "5-19 units",
grepl("_020$|_021$", variable) ~ "20+ units",
grepl("_022$|_023$", variable) ~ "Mobile Home/Other",
TRUE ~ NA_character_),
levels=c("Single Family","2-4 units","5-19 units", "20+ units", "Mobile Home/Other"))) %>%
mutate(building_size_2=factor(case_when(grepl("_014$", variable) ~ "Single Family",
grepl("_015$|_016$|_017$|_018$|_019$", variable) ~ "2-19 units",
grepl("_020$|_021$", variable) ~ "20+ units",
grepl("_022$|_023$", variable) ~ "Mobile Home/Other",
TRUE ~ NA_character_),
levels=c("Single Family","2-19 units", "20+ units", "Mobile Home/Other")
))
#--------------------Aggregate data, incorporate 2-19 Unit group------------------------
# In this step, you create an aggregate, using the grouping you created in the last call.
mmh_agg_renter <- summarize(mmh_raw, estimate=sum(estimate, na.rm=TRUE), moe=moe_sum(moe=moe, estimate=estimate, na.rm=TRUE))
# In this step, you create an aggregate, using the first grouping you created in the last call.
mmh_agg_renter_01 <- mmh_coded %>%
group_by(across(c(name, year, building_size))) %>%
summarize(estimate=sum(estimate, na.rm=TRUE), moe=moe_sum(moe=moe, estimate=estimate, na.rm=TRUE))
# In this step, you create an aggregate, using the second grouping you created.
mmh_agg_renter_02 <- mmh_coded %>%
group_by(across(c(name, year, building_size_2))) %>%
summarize(estimate=sum(estimate, na.rm=TRUE), moe=moe_sum(moe=moe, estimate=estimate, na.rm=TRUE)) %>%
filter(building_size_2 == '2-19 units') %>%
rename(building_size = building_size_2)
df <- mmh_agg_renter_01 %>%
bind_rows(mmh_agg_renter_02)
}
all_renter_tables <- map(years, ~create_mmh_renter_summary_table(.x)) %>%
reduce(bind_rows)
mmh_renter <- all_renter_tables %>%
mutate(building_size = factor(building_size,
levels = c('Single Family', '2-4 units', '5-19 units', '2-19 units', '20+ units', 'Mobile Home/Other'))) %>%
arrange(year, name, building_size) %>%
filter(building_size != is.na(building_size))
rm(list = setdiff(ls(), c("mmh_renter", "create_mmh_renter_summary_table", "mmh_owner", "create_mmh_owner_summary_table", "years")))
#------------------------Summarize existing housing stock------------------------
calc_share_growth <- function(table) {
# calculate totals in new dataframe
totals <- table %>%
filter(building_size != '2-19 units') %>%
group_by(name, year) %>%
summarise(total = sum(estimate))
# join to main table
table <- table %>%
left_join(totals, by = c('name', 'year'))
# calculate % of units by building size and % growth between years
table <- table %>%
mutate(share = estimate/total) %>%
arrange(name, building_size) %>%
group_by(name, building_size) %>%
mutate(growth = estimate-lag(estimate)) %>%
mutate(growth_share = growth/lag(total)) %>%
arrange(factor(name, levels = c('King County', 'Kitsap County', 'Pierce County', 'Snohomish County', 'Region')))
}
pivot_to_wide <- function(table) {
# wide format
growth_cols_head <- c(paste0('growth_', years[1:(length(years)-1)]), paste0('growth_share_', years[1:(length(years)-1)]))
growth_cols_tail <- rep(str_sub(years[-1], start = 3, end = 4), 2)
new_colnames <- map2(growth_cols_head, growth_cols_tail, ~paste0(.x, '-', .y)) %>% unlist()
old_colnames <- c(paste0('growth_', years[-1]), paste0('growth_share_', years[-1]))
names(old_colnames) <- new_colnames
# pivot to wide format
df <- table %>%
pivot_wider(id_cols = c('name', 'building_size'),
names_from = year,
values_from = c('estimate', 'moe', 'total', 'share', 'growth', 'growth_share'))
# rename growth columns
df <- df %>%
rename(all_of(old_colnames)) %>%
select(-ends_with(paste0('growth_', years[1])), -ends_with(paste0('growth_share_', years[1])))
}
# long format
df_mmh_owner <- calc_share_growth(mmh_owner)
df_mmh_renter <- calc_share_growth(mmh_renter)
# wide format (for excel)
df_mmh_owner_wide <- pivot_to_wide(df_mmh_owner)
df_mmh_renter_wide <- pivot_to_wide(df_mmh_renter)
share_cols_owner <- str_which(colnames(df_mmh_owner_wide), 'share')
share_cols_renter <- str_which(colnames(df_mmh_renter_wide), 'share')
View(df_mmh_owner_wide)
View(df_mmh_renter_wide)
library(tidyverse)
library(readxl)
library(janitor)
## 1) Set variables ---------------------------------------------------------------------
WSHFC_path <- "J:/Projects/IncomeRestrictedHsgDB/2022 vintage/Data/WSHFC/"
WSHFC_raw <- read_xlsx(paste0(WSHFC_path, "PSRC report for 2022.xlsx"))
vintage_year_cleaning_script = "2022"
address_script <- "./address_match.R"
remotes::install_github("slu-openGIS/postmastr")
source(address_script)
library(tidyverse)
library(readxl)
library(janitor)
## 1) Set variables ---------------------------------------------------------------------
WSHFC_path <- "J:/Projects/IncomeRestrictedHsgDB/2022 vintage/Data/WSHFC/"
WSHFC_raw <- read_xlsx(paste0(WSHFC_path, "PSRC report for 2022.xlsx"))
vintage_year_cleaning_script = "2022"
address_script <- "./address_match.R"
remotes::install_github("slu-openGIS/postmastr")
source(address_script)
setwd("C:/Users/eclute/GitHub/irhd")
library(tidyverse)
library(readxl)
library(janitor)
## 1) Set variables ---------------------------------------------------------------------
WSHFC_path <- "J:/Projects/IncomeRestrictedHsgDB/2022 vintage/Data/WSHFC/"
WSHFC_raw <- read_xlsx(paste0(WSHFC_path, "PSRC report for 2022.xlsx"))
vintage_year_cleaning_script = "2022"
address_script <- "./address_match.R"
remotes::install_github("slu-openGIS/postmastr")
source(address_script)
## 2) function --------------------------------------------------------------------
#create function to select and arrange columns needed for joining
select_and_arrange_columns_function <- function(df){
df <- df %>%
select(any_of(c("data_source",
"project_id",
"project_name",
"property_id",
"property_name",
"property_owner",
"manager",
"in_service_date",
"expiration_date",
"reported_address",
"city",
"zip",
"county",
"total_units",
"total_restricted_units",
"ami_20",
"ami_25",
"ami_30",
"ami_35",
"ami_40",
"ami_45",
"ami_50",
"ami_60",
"ami_65",
"ami_70",
"ami_75",
"ami_80",
"ami_85",
"ami_90",
"ami_100",
"ami_120",
"market_rate",
"manager_unit",
"bedroom_0",
"bedroom_1",
"bedroom_2",
"bedroom_3",
"bedroom_4",
"bedroom_5",
"bedroom_unknown",
"bed_count",
"site_type",
"home",
"HOMEcity",
"HOMEcounty",
"HOMEstate",
"confidentiality",
"policy",
"senior",
"disabled",
"farmworker",
"homeless",
"large_household",
"transitional",
"veterans",
"funding_sources",
"tenure")))
}
## 3) clean WSHFC data --------------------------------------------------------------------
# ------- DATA FILTER #1 ------- filter by county, create/modify fields
WSHFC_cleaned <- WSHFC_raw %>%
filter(County == "Snohomish" | County == "Pierce" | County == "Kitsap")
#create grouped funder column
WSHFC_cleaned %<>%
group_by(`Site Name`, Address) %>%
mutate(Funder = paste(sort(unique(Funder)), collapse = ","))
View(WSHFC_cleaned)
# ------- DATA FILTER #2 ------- select entry with the largest total restricted unit count
WSHFC_cleaned <- WSHFC_cleaned %>%
group_by(`Site Name`, Address) %>%
slice_max(`Income & Rent Restricted Units`,
n = 1,
with_ties = TRUE) %>%
distinct()
#check for duplicates
WSHFC_cleaned %>%
unique() %>%
group_by(`Site Name`, Address) %>%
mutate(n = n()) %>%
filter(n > 1) %>%
arrange(`Project Name`, `Site Name`, Address) # %>%
