grepl("^White ", race_ethnicity) ~"White",
grepl("^All", race_ethnicity) ~"All",
!is.na(race_ethnicity) ~ "")))
setDT(df)
df <- dcast.data.table(df, chas_year + geography_name + description ~ race_ethnicity, value.var = 'estimate')
# reorder rows
df <- df[, description := factor(description, levels = desc)][order(description)]
# calculate column total  ----
df_ra <- df[, Total := `American Indian or Alaskan Native` + `Asian` + `Black or African American` + `Hispanic or Latino (of any race)` +  `Pacific Islander` + `White`]
# calculate row totals/shares
df_ra <- df_ra %>%
bind_rows(summarise(., across(c(`American Indian or Alaskan Native`,`Asian`,`Black or African American`,`Hispanic or Latino (of any race)`,`Pacific Islander`,`White`,`Total`), sum),
across(description, ~'Total')))
df_ra[, `:=` (`American Indian or Alaskan Native_share` = `American Indian or Alaskan Native`/Total,
Asian_share = Asian/Total,
`Black or African American_share` = `Black or African American`/Total,
`Hispanic or Latino (of any race)_share` = `Hispanic or Latino (of any race)`/Total,
`Pacific Islander_share` = `Pacific Islander`/Total,
White_share = White/Total)]
View(df_ra)
View(all_dfs)
source('config.R')
library(dplyr)
chas_table <- c('T1')
dfs <- gather_tables(chas_table)
# Assemble Table ----
desc <- c('Extremely Low-Income (≤30% AMI)',
'Very Low-Income (30-50%)',
'Low-Income (50-80%)',
'Moderate Income (80-100%)',
'Above Median Income (>100%)')
cols <- c('variable_name', 'sort','chas_year', 'geography_name', 'estimate', 'moe',  'col_desc', 'race_ethnicity')
# Table 1 - select fields based on data vintage
ifelse(dfs$T1$chas_year <= '2014',
{ t1_head_30 <- c(134,130,131,133,132,129,143,175,171,172,174,173,170,184,216,212,213,215,214,211,225,10,6,7,9,8,5,11,51,47,48,50,49,46,52,92,88,89,91,90,87,93)
t1_head_30_50 <- c(142,138,139,141,140,137,151,183,179,180,182,181,178,192,224,220,221,223,222,219,233,18,14,15,17,16,13,19,59,55,56,58,57,54,60,100,96,97,99,98,95,101)
t1_head_50_80 <- c(150,146,147,149,148,145,159,191,187,188,190,189,186,200,232,228,229,231,230,227,241,26,22,23,25,24,21,27,67,63,64,66,65,62,68,108,104,105,107,106,103,109)
t1_head_80_100 <- c(158,154,155,157,156,153,159,199,195,196,198,197,194,200,240,236,237,239,238,235,241,34,30,31,33,32,29,35,75,71,72,74,73,70,76,116,112,113,115,114,111,117)
t1_head_100 <- c(166,162,163,165,164,161,167,207,203,204,206,205,202,208,248,244,245,247,246,243,249,42,38,39,41,40,37,43,83,79,80,82,81,78,84,124,120,121,123,122,119,125)
},
{ t1_head_30 <- c(10,6,7,9,8,5,46,42,43,45,44,41,83,79,80,82,81,78,119,115,116,118,117,114)
t1_head_30_50 <- c(17,13,14,16,15,12,53,49,50,52,51,48,90,86,87,89,88,85,126,122,123,125,124,121)
t1_head_50_80 <- c(24,20,21,23,22,19,60,56,57,59,58,55,97,93,94,96,95,92,133,129,130,132,131,128)
t1_head_80_100 <- c(31,27,28,30,29,26,67,63,64,66,65,62,104,100,101,103,102,99,140,136,137,139,138,135)
t1_head_100 <- c(38,34,35,37,36,33,74,70,71,73,72,69,111,107,108,110,109,106,147,143,144,146,145,142)
})
t1_30 <- dfs$T1[sort %in% t1_head_30, ]
t1_30 <- t1_30[, `:=`(sort = factor(sort, levels = t1_head_30), col_desc = 'Extremely Low-Income (≤30% AMI)')][order(sort)]
t1_30_50 <- dfs$T1[sort %in% t1_head_30_50, ]
t1_30_50 <- t1_30_50[, `:=`(sort = factor(sort, levels = t1_head_30_50), col_desc = 'Very Low-Income (30-50%)')][order(sort)]
t1_50_80 <- dfs$T1[sort %in% t1_head_50_80, ]
t1_50_80 <- t1_50_80[, `:=`(sort = factor(sort, levels = t1_head_50_80), col_desc = 'Low-Income (50-80%)')][order(sort)]
t1_80_100 <- dfs$T1[sort %in% t1_head_80_100, ]
t1_80_100 <- t1_80_100[, `:=`(sort = factor(sort, levels = t1_head_80_100), col_desc = 'Moderate Income (80-100%)')][order(sort)]
t1_100 <- dfs$T1[sort %in% t1_head_100, ]
t1_100 <- t1_100[, `:=`(sort = factor(sort, levels = t1_head_100), col_desc = 'Above Median Income (>100%)')][order(sort)]
all_dfs <-map(list(t1_30,t1_30_50,t1_50_80,t1_80_100,t1_100), ~.x[, ..cols])
df <- rbindlist(all_dfs)
df <- df %>%
group_by(col_desc, race_ethnicity) %>%
summarize(geography_name = first(geography_name),
estimate = sum(estimate),
chas_year = first(chas_year),
race_ethnicity = first(race_ethnicity))
# format Race/Ethnicity data
df$description <- df$col_desc
df <- df %>%
mutate(race_ethnicity=factor(case_when(grepl("^American Indian ", race_ethnicity) ~"American Indian or Alaskan Native",
grepl("^Asian ", race_ethnicity) ~"Asian",
grepl("^Black ", race_ethnicity) ~"Black or African American",
grepl("^Hispanic, any race", race_ethnicity) ~"Hispanic or Latino (of any race)",
grepl("^Pacific ", race_ethnicity) ~"Pacific Islander",
grepl("^White ", race_ethnicity) ~"White",
grepl("^All", race_ethnicity) ~"All",
!is.na(race_ethnicity) ~ "")))
# pivot wider
setDT(df)
df <- dcast.data.table(df, chas_year + geography_name + description ~ race_ethnicity, value.var = 'estimate')
# reorder rows
df <- df[, description := factor(description, levels = desc)][order(description)]
# calculate column total  ----
df_ra <- df[, Total := `American Indian or Alaskan Native` + `Asian` + `Black or African American` + `Hispanic or Latino (of any race)` +  `Pacific Islander` + `White`]
# calculate row totals/shares
df_ra <- df_ra %>%
bind_rows(summarise(., across(c(`American Indian or Alaskan Native`,`Asian`,`Black or African American`,`Hispanic or Latino (of any race)`,`Pacific Islander`,`White`,`Total`), sum),
across(description, ~'Total')))
df_ra[, `:=` (`American Indian or Alaskan Native_share` = `American Indian or Alaskan Native`/Total,
Asian_share = Asian/Total,
`Black or African American_share` = `Black or African American`/Total,
`Hispanic or Latino (of any race)_share` = `Hispanic or Latino (of any race)`/Total,
`Pacific Islander_share` = `Pacific Islander`/Total,
White_share = White/Total)]
View(df_ra)
source('config.R')
source('function-query-sqlite-chas.R')
library(dplyr)
library(tidyverse)
library(data.table)
# gather T1 table
chas_table <- c('T1')
dfs <- gather_tables(juris = 'tract',chas_table)
# source('config.R')
source('function-query-sqlite-chas.R')
# gather T1 table
chas_table <- c('T1')
dfs <- gather_tables(juris = 'tract',chas_table)
`%not_in%` <- Negate(`%in%`)
## load packages-----------------------------------------------------------------
library(tidyverse)
library(tidyr)
library(readxl)
library(data.table)
library(magrittr)
library(stringr)
IRHD_path <- "J:/Projects/IncomeRestrictedHsgDB/2021 vintage/Data/1 Working Files/2021 IRHD v3 - ready4reconcilescript.csv"
WSHFC_path <- "J:/Projects/IncomeRestrictedHsgDB/2021 vintage/WSHFC/Cleaned Data/WSHFC_2021_cleaned.csv"
script_path <- "address_match.R"
file_path <- "C:/Users/eclute/OneDrive - Puget Sound Regional Council/Documents/GitHub/irhd/Export4review.csv"
source(script_path)
setwd("~/GitHub/irhd")
`%not_in%` <- Negate(`%in%`)
## load packages-----------------------------------------------------------------
library(tidyverse)
library(tidyr)
library(readxl)
library(data.table)
library(magrittr)
library(stringr)
IRHD_path <- "J:/Projects/IncomeRestrictedHsgDB/2021 vintage/Data/1 Working Files/2021 IRHD v3 - ready4reconcilescript.csv"
WSHFC_path <- "J:/Projects/IncomeRestrictedHsgDB/2021 vintage/WSHFC/Cleaned Data/WSHFC_2021_cleaned.csv"
script_path <- "address_match.R"
file_path <- "C:/Users/eclute/OneDrive - Puget Sound Regional Council/Documents/GitHub/irhd/Export4review.csv"
source(script_path)
## 1) load data ---------------------------------------------------------------------
#load cleaned 2021 IRHD that has portfolios as of end of 2021
IRHD_raw <- fread(IRHD_path)
# borrow datatype characterization from IRHD to apply to identical columns in WSHFC data
irhd_colClasses = sapply(IRHD_raw, class)
names(irhd_colClasses) <- colnames(IRHD_raw)
WSHFC_cols = colnames(read.csv(WSHFC_path, nrows=1))
wshfc_colClasses <- irhd_colClasses %>% .[names(.) %in% WSHFC_cols]
#load cleaned WSHFC data that has portfolios as of end of 2021; apply datatypes to match
WSHFC_raw <- fread(WSHFC_path, colClasses=wshfc_colClasses)
#load cleaned KC data that has portfolios as of end of 2021
# KC21raw <- read_csv("J:/Projects/IncomeRestrictedHsgDB/2021 vintage/Review Files - Received/")
## 2) clean up fields in IRHD, limit to 3 counties, add/remove fields --------------------------------------------------------------------
IRHD_raw %<>% .[County %in% c("Pierce", "Snohomish", "Kitsap")]                                    # King county handled separately
IRHD_raw %<>% .[, grep("\\d+-\\d+%", colnames(.)):=NULL]                                           # Remove summary AMI fields
# Create three new HOME fields
IRHD_raw %<>% mutate(HOMEcity = NA_character_,                                                     # Add fields to match WSHFC
HOMEcounty = NA_character_,
HOMEstate = NA_character_,
.after = HOME)
# Manage duplicate records in IRHD
IRHD_raw %<>%  filter(!(UniqueID == "SH_7002")) %>% # Remove this record, keep SH_6053
filter(!(UniqueID == "SH_6516")) # Remove this record, keep SH_6517
# Remove Jurisdiction and cityFIPS fields, we will calculate these in Elmer going forward
IRHD_raw %<>% select(-c(Jurisdiction,CityFIPS))
IRHD_raw$fulladdress <- str_c(IRHD_raw$Address,', ',IRHD_raw$City,', WA, ',IRHD_raw$ZIP)
IRHD_raw <- add_cleaned_addresses(IRHD_raw) %>% setDT()
str(IRHD_raw)
## 3) clean up some variables in WSHFC before joining --------------------------------------------------------------------
IRHD_raw$Manager[IRHD_raw$Manager == 'HASCO'] <- 'Snohomish County Housing Authority'
IRHD_raw$Owner[IRHD_raw$Owner == 'HASCO'] <- 'Snohomish County Housing Authority'
IRHD_raw$Manager[IRHD_raw$Manager == 'Low Income Housing Institute'] <- 'Low Income Housing Institute (LIHI)'
IRHD_raw$Owner[IRHD_raw$Owner == 'Low Income Housing Institute'] <- 'Low Income Housing Institute (LIHI)'
WSHFC_raw$Address[WSHFC_raw$Address == '1724 E. 44th'] <- '1724 E 44th Street'
WSHFC_raw$Address[WSHFC_raw$Address == '9225 Bayshore Drive NW'] <- '9225 Bay Shore Dr NW'
WSHFC_raw$Address[WSHFC_raw$Address == '9239 Bayshore Dr NW'] <- '9239 Bay Shore Dr NW'
# Clean Address field for matching
remotes::install_github("slu-openGIS/postmastr")
source("C:/Users/eclute/OneDrive - Puget Sound Regional Council/Documents/GitHub/irhd/address_match.R")
library(stringr)
WSHFC_raw$fulladdress <- str_c(WSHFC_raw$Address,', ',WSHFC_raw$City,', WA, ',WSHFC_raw$ZIP)
WSHFC_raw <- add_cleaned_addresses(WSHFC_raw)
str(WSHFC_raw)
## 4) Locate records in WSHFC not in IRHD (likely new records/properties) --------------------------------------------------------------------
newWSHFC <- anti_join(WSHFC_raw, IRHD_raw, by = "PropertyID")
newWSHFC <- newWSHFC[ , !names(newWSHFC) %in% c("Farmworker")]
## 5) Locate records in IRHD not in WSHFC (No longer in WSHFC data, but once were?) --------------------------------------------------------------------
nomatchIRHD <- anti_join(IRHD_raw, WSHFC_raw, by = "PropertyID")
nomatchIRHD <- nomatchIRHD %>% drop_na(PropertyID)
# 7/5/23 after confirmation from Commerce/WSHFC, these missing properties were accidentally excluded from the 2021 WSHFC dataset
# KEEP all these records in IRHD. 2022 WSHFC dataset should include these. Next time, properties in 'nomatchIRHD' will need to be verified (did they go offline, etc?)
## 6) Identify matched records in IRHD and WSHFC --------------------------------------------------------------------
# Pivot the IRHD_raw data to make it long and thin
long_IRHD <- IRHD_raw %>%
pivot_longer(c('ProjectID',
'ProjectName',
'PropertyName',
'Owner',
'Manager',
'InServiceDate',
'ExpirationDate',
'cleaned.address',
'County',
'TotalUnits',
'TotalRestrictedUnits',
'AMI20','AMI25','AMI30','AMI35','AMI40','AMI45','AMI50','AMI60','AMI65','AMI70','AMI75','AMI80','AMI85','AMI90','AMI100',
'MarketRate',
'ManagerUnit',
'Bedroom_0','Bedroom_1','Bedroom_2','Bedroom_3','Bedroom_4','Bedroom_5','Bedroom_Unknown',
'BedCount',
'Site_Type',
'HOMEcity',
'HOMEcounty',
'HOMEstate',
'Confidentiality',
'Policy',
'Senior',
'Disabled',
'Homeless',
'Transitional',
'Veterans',
'FundingSources',
'Tenure'),
names_to='variable_class',
values_to='variable_value',
values_transform = list(variable_value=as.character))
# Remove some fields that we don't need here
long_IRHD %<>% select(c(PropertyID,variable_class,variable_value))
# Pivot the mocked-up data to make it long and thin
long_WSHFC <- WSHFC_raw %>%
pivot_longer(c('ProjectID',
'ProjectName',
'PropertyName',
'Owner',
'Manager',
'InServiceDate',
'ExpirationDate',
'cleaned.address',
'County',
'TotalUnits',
'TotalRestrictedUnits',
'AMI20','AMI25','AMI30','AMI35','AMI40','AMI45','AMI50','AMI60','AMI65','AMI70','AMI75','AMI80','AMI85','AMI90','AMI100',
'MarketRate',
'ManagerUnit',
'Bedroom_0','Bedroom_1','Bedroom_2','Bedroom_3','Bedroom_4','Bedroom_5','Bedroom_Unknown',
'BedCount',
'Site_Type',
'HOMEcity',
'HOMEcounty',
'HOMEstate',
'Confidentiality',
'Policy',
'Senior',
'Disabled',
'Homeless',
'Transitional',
'Veterans',
'FundingSources',
'Tenure'),
names_to='variable_class',
values_to='variable_value',
values_transform = list(variable_value=as.character))
# Remove some fields that we don't need here
long_WSHFC %<>% select(c(PropertyID,variable_class,variable_value))
# Compare the two data sets in long form to identify values that have been changed
long_compare <- long_IRHD %>%
inner_join(long_WSHFC, by=c('PropertyID', 'variable_class')) %>%
mutate("match" = ifelse(mapply(identical, variable_value.x, variable_value.y), "YES", "NO")) %>%
filter(match == "NO") %>%
drop_na(variable_value.y)
## 7) Identify which rows will be updated with new WSHFC data, or keep existing data --------------------------------------------------------------------
# Create field to indicate which variable to use
long_compare$select <- ""
long_compare <- tibble::rowid_to_column(long_compare, "ID")
# Subset 1) select records with no data in the IRHD - we will take new data from WSHFC
subset1 <- long_compare %>% subset((is.na(variable_value.x)| variable_value.x == ""), select = c(ID, PropertyID, variable_class,variable_value.x,variable_value.y,match, select))
subset1$select <- subset1$variable_value.y
long_compare <- anti_join(long_compare, subset1, by=c("ID"="ID")) # remove from long_compare
selected <- subset1
rm(subset1)
# Subset 2) Below fields - select WHSFC data
subset2 <- long_compare %>% subset((variable_class == "InServiceDate" |
variable_class == "Manager"|
variable_class == "Owner"|
variable_class == "ProjectID"|
variable_class == "Disabled"|
variable_class == "Homeless"|
variable_class == "Senior"|
variable_class == "BedCount"|
variable_class == "PropertyName"|
variable_class == "Site_Type"|
variable_class == "FundingSources"|
variable_class == "HOMEcity"|
variable_class == "HOMEcounty"|
variable_class == "HOMEstate"|
variable_class == "ProjectName"), select = c(ID, PropertyID, variable_class,variable_value.x,variable_value.y,match, select))
subset2$select <- subset2$variable_value.y
long_compare <- anti_join(long_compare, subset2, by=c("ID"="ID")) # remove from long_compare
selected <- rbind(selected, subset2)
rm(subset2)
# Subset 3) select addresses that have "multiple" in the field - use IRHD address
subset3 <- long_compare %>% subset(str_detect(long_compare$variable_value.y, str_c("Mu")), select = c(ID, PropertyID, variable_class,variable_value.x,variable_value.y,match, select))
subset3$select <- subset3$variable_value.x
long_compare <- anti_join(long_compare, subset3, by=c("ID"="ID"))# remove from long_compare
selected <- rbind(selected, subset3)
rm(subset3)
# Subset 4) select all AMI/Unit count/Bedroom size data, identify small numeric changes
subset4 <- long_compare %>% subset((variable_class == "TotalUnits" |
variable_class == "TotalRestrictedUnits"|
variable_class == "AMI20"|
variable_class == "AMI25"|
variable_class == "AMI30"|
variable_class == "AMI35"|
variable_class == "AMI40"|
variable_class == "AMI45"|
variable_class == "AMI50"|
variable_class == "AMI60"|
variable_class == "AMI65"|
variable_class == "AMI70"|
variable_class == "AMI75"|
variable_class == "AMI80"|
variable_class == "AMI85"|
variable_class == "AMI90"|
variable_class == "AMI100"|
variable_class == "MarketRate"|
variable_class == "ManagerUnit"|
variable_class == "Bedroom_0"|
variable_class == "Bedroom_1"|
variable_class == "Bedroom_2"|
variable_class == "Bedroom_3"|
variable_class == "Bedroom_4"|
variable_class == "Bedroom_5"|
variable_class == "Bedroom_Unknown"|
variable_class == "BedCount"), select = c(ID, PropertyID, variable_class,variable_value.x,variable_value.y,match, select))
# Create formula for calculating difference between numeric values
subset4_sum <- subset4 %>% group_by(PropertyID) %>%
summarize(sum.x=sum(as.numeric(variable_value.x)),
sum.y=sum(as.numeric(variable_value.y)))
# abs function - absolute value of the percentage difference
subset4_sum$diff <- abs((subset4_sum$sum.x-subset4_sum$sum.y)/subset4_sum$sum.x)
# join back to subset4 table, so each row of data now has the percentage difference
subset4 <- merge(subset4, subset4_sum, by = "PropertyID")
rm(subset4_sum)
# Rows with "diff" of 12% or less will be selected - we want the WSHFC data
subset4$select <- ifelse(subset4$diff <= "0.12", subset4$variable_value.y, "")
# Rows where the sum.y is 0, we keep the sum.x data (if WSHFC data is 0, we keep IRHD data)
subset4$select <- ifelse(subset4$sum.y == "0", subset4$variable_value.x, subset4$select)
# Remove "diff" of greater than 12% from subset4
subset4 <- subset4 %>% subset(!(select == ""), select = c(ID, PropertyID, variable_class,variable_value.x,variable_value.y,match, select, sum.x, sum.y, diff))
long_compare <- anti_join(long_compare, subset4, by=c("ID"="ID")) # remove from long_compare
subset4 <- subset4[, -c(8,9,10)]
selected <- rbind(selected, subset4)
rm(subset4)
# Subset 5) If WSHFC field is blank, select IRHD data
subset5 <- long_compare %>% subset((is.na(variable_value.y)| variable_value.y == ""), select = c(ID, PropertyID, variable_class,variable_value.x,variable_value.y,match, select))
subset5$select <- subset5$variable_value.x
long_compare <- anti_join(long_compare, subset5, by=c("ID"="ID")) # remove from long_compare
selected <- rbind(selected, subset5)
rm(subset5)
# Subset 6-10) Various manual selections of the remaining rows
subset6 <- long_compare %>% subset(str_detect(long_compare$variable_value.y, str_c("303 Howell Way & 417 3rd Ave, Edmonds, WA 98020")), select = c(ID, PropertyID, variable_class,variable_value.x,variable_value.y,match, select))
subset6$select <- subset6$variable_value.x
long_compare <- anti_join(long_compare, subset6, by=c("ID"="ID"))# remove from long_compare
selected <- rbind(selected, subset6)
rm(subset6)
subset7 <- long_compare %>% subset(str_detect(long_compare$variable_value.y, " Rainier Ave, Everett, WA 98201"), select = c(ID, PropertyID, variable_class,variable_value.x,variable_value.y,match, select))
subset7$select <- subset7$variable_value.x
long_compare <- anti_join(long_compare, subset7, by=c("ID"="ID"))# remove from long_compare
selected <- rbind(selected, subset7)
rm(subset7)
subset8 <- long_compare %>% subset(str_starts(long_compare$variable_value.y, ("[:alpha:]")), select = c(ID, PropertyID, variable_class,variable_value.x,variable_value.y,match, select))
subset8$select <- subset8$variable_value.x
long_compare <- anti_join(long_compare, subset8, by=c("ID"="ID"))# remove from long_compare
selected <- rbind(selected, subset8)
rm(subset8)
subset9 <- long_compare %>% subset(str_detect(long_compare$PropertyID, "18015|18016|16100|16101|16402|16002|18092|16002"), select = c(ID, PropertyID, variable_class,variable_value.x,variable_value.y,match, select))
subset9$select <- subset9$variable_value.x
long_compare <- anti_join(long_compare, subset9, by=c("ID"="ID"))# remove from long_compare
selected <- rbind(selected, subset9)
rm(subset9)
subset10 <- long_compare %>% subset(str_detect(long_compare$PropertyID, "18210|16044"), select = c(ID, PropertyID, variable_class,variable_value.x,variable_value.y,match, select))
subset10$select <- subset10$variable_value.y
long_compare <- anti_join(long_compare, subset10, by=c("ID"="ID"))# remove from long_compare
selected <- rbind(selected, subset10)
rm(subset10)
# Export remaining records and contact the corresponding housing authority
export_longcompare <- long_compare %>%
inner_join(IRHD_raw, by='PropertyID')
export_longcompare = export_longcompare[,c("ID","PropertyID","variable_class","variable_value.x","variable_value.y","DataSource","ProjectName","Owner","InServiceDate", "County","cleaned.address")]
write.csv(export_longcompare, file_path, row.names=FALSE)
## 8) Take "selected" data and update IRHD records, create IRHD_clean table --------------------------------------------------------------------
# Transform "selected" for updating existing IRHD
selected <- selected %>% pivot_wider(id_cols = c('PropertyID'), names_from = 'variable_class', values_from = 'select') %>%
setDT()
class(selected$ProjectID) = "numeric"
class(selected$TotalUnits) = "numeric"
class(selected$TotalRestrictedUnits) = "numeric"
class(selected$ZIP) = "numeric"
class(selected$AMI30) = "numeric"
class(selected$AMI35) = "numeric"
class(selected$AMI40) = "numeric"
class(selected$AMI45) = "numeric"
class(selected$AMI50) = "numeric"
class(selected$AMI60) = "numeric"
class(selected$AMI65) = "numeric"
class(selected$AMI80) = "numeric"
class(selected$Bedroom_1) = "numeric"
class(selected$Bedroom_2) = "numeric"
class(selected$Bedroom_3) = "numeric"
class(selected$Bedroom_4) = "numeric"
class(selected$Bedroom_Unknown) = "numeric"
class(selected$BedCount) = "numeric"
class(selected$Senior) = "numeric"
class(selected$Homeless) = "numeric"
class(selected$Disabled) = "numeric"
# Create new clean IRHD file
IRHD_clean <- copy(IRHD_raw)
# Update records as determined by the "selected" dataframe
shared_fields <- intersect(names(selected), names(IRHD_clean))                                     # fields in common
dupes <- IRHD_clean[duplicated(PropertyID), cbind(.SD[1], number=.N), by=PropertyID] %>%           # duplicates (to exclude)
pull(UniqueID)
blankfill <- IRHD_clean %>%                                                                        # create IRHD data that matches fields from selected
.[!is.na(PropertyID) & UniqueID %not_in% (dupes), (colnames(.) %in% shared_fields), with=FALSE]  # include only common records, no duplicate keys
selected %<>% rows_patch(blankfill, by="PropertyID", unmatched="ignore")                           # replace NA in `selected` with values from `IRHD_clean`
IRHD_clean %<>% .[selected, (shared_fields):=mget(paste0("i.", shared_fields)), on=.(PropertyID)]  # carry over all matching variables from selected
rm(dupes, blankfill, shared_fields, long_IRHD, long_WSHFC, wshfc_colClasses, WSHFC_cols, irhd_colClasses, long_compare) # Clean up
# Add in new properties identified in newWSHFC
newWSHFC$HOMEcity <- as.character(newWSHFC$HOMEcity)
newWSHFC$HOMEcounty <- as.character(newWSHFC$HOMEcounty)
newWSHFC$HOMEstate <- as.character(newWSHFC$HOMEstate)
IRHD_clean <- bind_rows(IRHD_clean, newWSHFC)
View(IRHD_clean)
max(IRHD_clean$UniqueID)
IRHD_clean[which.max(IRHD_clean$UniqueID),]
substrRight(IRHD_clean$UniqueID, 4)
str_sub(IRHD_clean$UniqueID, start= -6)
str_sub(IRHD_clean$UniqueID, start= -5)
str_sub(IRHD_clean$UniqueID, start= -4)
IRHD_clean$tempID <- str_sub(IRHD_clean$UniqueID, start= -4)
str_sub(IRHD_clean$UniqueID, start= -4)
max(IRHD_clean$tempID)
max(na.omit(IRHD_clean$tempID))
# Create new UniqueID value for each new record
IRHD_clean$tempID <- str_sub(IRHD_clean$UniqueID, start= -4)
IRHD_clean$UniqueID[IRHD_clean$UniqueID == "" | is.na(IRHD_clean$UniqueID) ] <- paste("SH_", max(na.omit(IRHD_clean$tempID))+1)
IRHD_clean$UniqueID[IRHD_clean$UniqueID == "" | is.na(IRHD_clean$UniqueID) ] <- paste("SH_", max(na.omit(IRHD_clean$tempID)))
IRHD_clean <- copy(IRHD_raw)
# Update records as determined by the "selected" dataframe
shared_fields <- intersect(names(selected), names(IRHD_clean))                                     # fields in common
dupes <- IRHD_clean[duplicated(PropertyID), cbind(.SD[1], number=.N), by=PropertyID] %>%           # duplicates (to exclude)
pull(UniqueID)
blankfill <- IRHD_clean %>%                                                                        # create IRHD data that matches fields from selected
.[!is.na(PropertyID) & UniqueID %not_in% (dupes), (colnames(.) %in% shared_fields), with=FALSE]  # include only common records, no duplicate keys
selected %<>% rows_patch(blankfill, by="PropertyID", unmatched="ignore")                           # replace NA in `selected` with values from `IRHD_clean`
IRHD_clean %<>% .[selected, (shared_fields):=mget(paste0("i.", shared_fields)), on=.(PropertyID)]  # carry over all matching variables from selected
rm(dupes, blankfill, shared_fields, long_IRHD, long_WSHFC, wshfc_colClasses, WSHFC_cols, irhd_colClasses, long_compare) # Clean up
# Add in new properties identified in newWSHFC
newWSHFC$HOMEcity <- as.character(newWSHFC$HOMEcity)
newWSHFC$HOMEcounty <- as.character(newWSHFC$HOMEcounty)
newWSHFC$HOMEstate <- as.character(newWSHFC$HOMEstate)
IRHD_clean <- bind_rows(IRHD_clean, newWSHFC)
# Create new UniqueID value for each new record
IRHD_clean$tempID <- str_sub(IRHD_clean$UniqueID, start= -4)
IRHD_clean$UniqueID[IRHD_clean$UniqueID == "" | is.na(IRHD_clean$UniqueID) ] <- paste("SH_", max(na.omit(IRHD_clean$tempID)), +1)
IRHD_clean <- copy(IRHD_raw)
# Update records as determined by the "selected" dataframe
shared_fields <- intersect(names(selected), names(IRHD_clean))                                     # fields in common
dupes <- IRHD_clean[duplicated(PropertyID), cbind(.SD[1], number=.N), by=PropertyID] %>%           # duplicates (to exclude)
pull(UniqueID)
blankfill <- IRHD_clean %>%                                                                        # create IRHD data that matches fields from selected
.[!is.na(PropertyID) & UniqueID %not_in% (dupes), (colnames(.) %in% shared_fields), with=FALSE]  # include only common records, no duplicate keys
selected %<>% rows_patch(blankfill, by="PropertyID", unmatched="ignore")                           # replace NA in `selected` with values from `IRHD_clean`
IRHD_clean %<>% .[selected, (shared_fields):=mget(paste0("i.", shared_fields)), on=.(PropertyID)]  # carry over all matching variables from selected
rm(dupes, blankfill, shared_fields, long_IRHD, long_WSHFC, wshfc_colClasses, WSHFC_cols, irhd_colClasses, long_compare) # Clean up
# Add in new properties identified in newWSHFC
newWSHFC$HOMEcity <- as.character(newWSHFC$HOMEcity)
newWSHFC$HOMEcounty <- as.character(newWSHFC$HOMEcounty)
newWSHFC$HOMEstate <- as.character(newWSHFC$HOMEstate)
IRHD_clean <- bind_rows(IRHD_clean, newWSHFC)
# Create new UniqueID value for each new record
IRHD_clean$tempID <- str_sub(IRHD_clean$UniqueID, start= -4)
IRHD_clean$tempID[IRHD_clean$tempID == "" | is.na(IRHD_clean$tempID) ] <- paste(max(na.omit(IRHD_clean$tempID)), +1)
IRHD_clean <- copy(IRHD_raw)
# Update records as determined by the "selected" dataframe
shared_fields <- intersect(names(selected), names(IRHD_clean))                                     # fields in common
dupes <- IRHD_clean[duplicated(PropertyID), cbind(.SD[1], number=.N), by=PropertyID] %>%           # duplicates (to exclude)
pull(UniqueID)
blankfill <- IRHD_clean %>%                                                                        # create IRHD data that matches fields from selected
.[!is.na(PropertyID) & UniqueID %not_in% (dupes), (colnames(.) %in% shared_fields), with=FALSE]  # include only common records, no duplicate keys
selected %<>% rows_patch(blankfill, by="PropertyID", unmatched="ignore")                           # replace NA in `selected` with values from `IRHD_clean`
IRHD_clean %<>% .[selected, (shared_fields):=mget(paste0("i.", shared_fields)), on=.(PropertyID)]  # carry over all matching variables from selected
rm(dupes, blankfill, shared_fields, long_IRHD, long_WSHFC, wshfc_colClasses, WSHFC_cols, irhd_colClasses, long_compare) # Clean up
# Add in new properties identified in newWSHFC
newWSHFC$HOMEcity <- as.character(newWSHFC$HOMEcity)
newWSHFC$HOMEcounty <- as.character(newWSHFC$HOMEcounty)
newWSHFC$HOMEstate <- as.character(newWSHFC$HOMEstate)
IRHD_clean <- bind_rows(IRHD_clean, newWSHFC)
# Create new UniqueID value for each new record
IRHD_clean$tempID <- str_sub(IRHD_clean$UniqueID, start= -4)
IRHD_clean$tempID[IRHD_clean$tempID == "" | is.na(IRHD_clean$tempID) ] <- paste(max(na.omit(IRHD_clean$tempID)) +1)
IRHD_clean <- copy(IRHD_raw)
# Update records as determined by the "selected" dataframe
shared_fields <- intersect(names(selected), names(IRHD_clean))                                     # fields in common
dupes <- IRHD_clean[duplicated(PropertyID), cbind(.SD[1], number=.N), by=PropertyID] %>%           # duplicates (to exclude)
pull(UniqueID)
blankfill <- IRHD_clean %>%                                                                        # create IRHD data that matches fields from selected
.[!is.na(PropertyID) & UniqueID %not_in% (dupes), (colnames(.) %in% shared_fields), with=FALSE]  # include only common records, no duplicate keys
selected %<>% rows_patch(blankfill, by="PropertyID", unmatched="ignore")                           # replace NA in `selected` with values from `IRHD_clean`
IRHD_clean %<>% .[selected, (shared_fields):=mget(paste0("i.", shared_fields)), on=.(PropertyID)]  # carry over all matching variables from selected
rm(dupes, blankfill, shared_fields, long_IRHD, long_WSHFC, wshfc_colClasses, WSHFC_cols, irhd_colClasses, long_compare) # Clean up
# Add in new properties identified in newWSHFC
newWSHFC$HOMEcity <- as.character(newWSHFC$HOMEcity)
newWSHFC$HOMEcounty <- as.character(newWSHFC$HOMEcounty)
newWSHFC$HOMEstate <- as.character(newWSHFC$HOMEstate)
IRHD_clean <- bind_rows(IRHD_clean, newWSHFC)
# Create new UniqueID value for each new record
IRHD_clean$tempID <- str_sub(IRHD_clean$UniqueID, start= -4)
IRHD_clean$tempID[IRHD_clean$tempID == "" | is.na(IRHD_clean$tempID) ] <- add(max(na.omit(IRHD_clean$tempID)),1)
IRHD_clean <- subset(IRHD_clean, select = -c(tempID))
